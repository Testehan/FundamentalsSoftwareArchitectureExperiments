The software development ecosystem exists in a constant state of dynamic equili‐
brium: while it exists in a balanced state at any given point in time, it exhibits
dynamic behavior over the long term. A great modern example of the nature of this
ecosystem follows the ascension of containerization and the attendant changes: tools
like Kubernetes didn’t exist a decade ago, yet now entire software conferences exist to
service its users. The software ecosystem changes chaotically: one small change
causes another small change; when repeated hundreds of times, it generates a new
ecosystem.

As capabilities changed, so did architects’ perspectives on the industry. For
many years, the tongue-in-cheek definition of software architecture was “the stuff
that’s hard to change later.” Later, the microservices architecture style appeared, where
change is a first-class design consideration

As a software developer, it’s easy to become enamored with a particular technology or approach.
But architects must always soberly assess the good, bad, and ugly of every choice, and
virtually nothing in the real world offers convenient binary choices—everything is a
trade-off

This book won’t make someone a software architect overnight—it’s a nuanced field
with many facets. We want to provide existing and burgeoning architects a good
modern overview of software architecture and its many aspects, from structure to soft
skills.

========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
PART I Foundations


========================================================================================================================
Chapter 1. Introduction

    Why is there no path for software architects?
    First, the industry doesn’t have a good definition of software architecture itself. When
    we teach foundational classes, students often ask for a concise definition of what a
    software architect does, and we have adamantly refused to give one. And we’re not
    the only ones. In his famous whitepaper “Who Needs an Architect?” Martin Fowler
    famously refused to try to define it, instead falling back on the famous quote:
        Architecture is about the important stuff…whatever that is.
             —Ralph Johnson

    When studying architecture, readers must keep in mind that, like much art, it can
    only be understood in context. Many of the decisions architects made were based on
    realities of the environment they found themselves in. For example, one of the major
    goals of late 20th-century architecture included making the most efficient use of
    shared resources, because all the infrastructure at the time was expensive and com‐
    mercial: operating systems, application servers, database servers, and so on. Imagine
    strolling into a 2002 data center and telling the head of operations “Hey, I have a great
    idea for a revolutionary style of architecture, where each service runs on its own iso‐
    lated machinery, with its own dedicated database (describing what we now know as
    microservices). So, that means I’ll need 50 licenses for Windows, another 30 applica‐
    tion server licenses, and at least 50 database server licenses.” In 2002, trying to build
    an architecture like microservices would be inconceivably expensive. Yet, with the
    advent of open source during the intervening years, coupled with updated engineer‐
    ing practices via the DevOps revolution, we can reasonably build an architecture as
    described

!!!!!
    In this definition, software architecture consists of:
        -the structure of the system (denoted  as the heavy black lines supporting the architecture)
            such as microservices, layered, or microkernel
        -architecture characteristics (“-ilities”) the system must support
            define the success criteria of a system : Availability, Scalability, Security, Performance, Fault tolerance etc
        -architecture decisions
            Architecture decisions define the rules for how a system should be constructed. For example,
            an architect might make an architecture decision that only the business and services
            layers within a layered architecture can access the database (see Figure 1-5), restrict‐
            ing the presentation layer from making direct database calls.
            Architecture decisions form the constraints of the system and direct the development
            teams on what is and what isn’t allowed
        -design principles
            A design principle differs from an architecture decision in that a design principle is a
            guideline rather than a hard-and-fast rule. For example, the design principle illustrated in
            Figure 1-6 states that the development teams should leverage asynchronous messaging between
            services within a microservices architecture to increase performance.
!!!!!!

    Expectations of an Architect
        Defining the role of a software architect presents as much difficulty as defining soft‐
        ware architecture. It can range from expert programmer up to defining the strategic
        technical direction for the company. Rather than waste time on the fool’s errand of
        defining the role, we recommend focusing on the expectations of an architect.
        There are eight core expectations placed on a software architect, irrespective of any
        given role, title, or job description:
            • Make architecture decisions
                An architect is expected to define the architecture decisions and design principles used to
                guide technology decisions within the team, the department, or across the enterprise.
            • Continually analyze the architecture
                An architect is expected to continually analyze the architecture and current technology
                environment and then recommend solutions for improvement
            • Keep current with latest trends
                The decisions an architect makes tend to be long-lasting and difficult to change.
                Understanding and following key trends helps the architect prepare for the future and make the correct
                decision.
            • Ensure compliance with decisions
                Ensuring compliance means that the architect is continually verifying that develop‐
                ment teams are following the architecture decisions and design principles defined,
                documented, and communicated by the architect.
            • Diverse exposure and experience
                This expectation does not mean an architect must be an expert in every framework,
                platform, and language, but rather that an architect must at least be familiar with a
                variety of technologies
                A good way of mastering this expectation is to focus on technical breadth rather than technical depth.
                Technical breadth includes the stuff you know about, but not at a detailed level, com‐
                bined with the stuff you know a lot about. For example, it is far more valuable for an
                architect to be familiar with 10 different caching products and the associated pros
                and cons of each rather than to be an expert in only one of them
            • Have business domain knowledge
                The most successful architects we know are those who have broad, hands-on techni‐
                cal knowledge coupled with a strong knowledge of a particular domain. These soft‐
                ware architects are able to effectively communicate with C-level executives and
                business users using the domain knowledge and language that these stakeholders
                know and understand. This in turn creates a strong level of confidence that the soft‐
                ware architect knows what they are doing and is competent to create an effective and
                correct architecture.
            • Possess interpersonal skills
                As technologists, developers and architects like to
                solve technical problems, not people problems. However, as Gerald Weinberg was
                famous for saying, “no matter what they tell you, it’s always a people problem.” An
                architect is not only expected to provide technical guidance to the team, but is also
                expected to lead the development teams through the implementation of the architec‐
                ture. Leadership skills are at least half of what it takes to become an effective software
                architect, regardless of the role or title the architect has.

                We’ve known many software architects who are excellent technolo‐
                gists but are ineffective architects due to the inability to lead teams, coach and mentor
                developers, and effectively communicate ideas and architecture decisions and principles.
            • Understand and navigate politics
                The main point is that almost every decision an architect makes will be challenged.
                Architectural decisions will be challenged by product owners, project managers, and
                business stakeholders due to increased costs or increased effort (time) involved.
                This fact can be very frustrating to a software architect, because most decisions made as a developer did
                not require approval or even a review


    As any experience in the software development world illustrates, nothing remains
    static. Thus, architects may design a system to meet certain criteria, but that design
    must survive both implementation (how can architects make sure that their design is
    implemented correctly) and the inevitable change driven by the software develop‐
    ment ecosystem. What we need is an evolutionary architecture.

    Building Evolutionary Architectures introduces the concept of using fitness functions to
    protect (and govern) architectural characteristics as change occurs over time.

    Building Evolutionary Architectures co-opts this idea to create architectural fitness
    functions: an objective integrity assessment of some architectural characteristic(s).
    This assessment may include a variety of mechanisms, such as metrics, unit tests,
    monitors, and chaos engineering. For example, an architect may identify page load
    time as an importance characteristic of the architecture. To allow the system to
    change without degrading performance, the architecture builds a fitness function as a
    test that measures page load time for each page and then runs the test as part of the
    continuous integration for the project. Thus, architects always know the status of crit‐
    ical parts of the architecture because they have a verification mechanism in the form
    of fitness functions for each part.

!!!!
    Laws of Software Architecture
        Everything in software architecture is a trade-off.
            —First Law of Software Architecture

        If an architect thinks they have discovered something that isn’t a trade-off, more likely
        they just haven’t identified the trade-off yet.
            —Corollary 1

        Why is more important than how.
            —Second Law of Software Architecture

            An architect can look at an existing system they have no knowledge of and ascertain how the structure of the
            architecture works, but will struggle explaining why certain choices were made versus others


========================================================================================================================
Chapter 2. Architectural Thinking

    An architect sees things differently from a developer’s point of view, much in the
    same way a meteorologist might see clouds differently from an artist’s point of view.
    This is called architectural thinking. Unfortunately, too many architects believe that
    architectural thinking is simply just “thinking about the architecture.”

!!!!
    Architectural thinking is much more than that. It is seeing things with an architec‐
    tural eye, or an architectural point of view. There are four main aspects of thinking
    like an architect:
        -First, it’s understanding the difference between architecture and
        design and knowing how to collaborate with development teams to make architecture work.
        - Second, it’s about having a wide breadth of technical knowledge while still
         maintaining a certain level of technical depth, allowing the architect to see solutions
         and possibilities that others do not see.
        - Third, it’s about understanding, analyzing,  and reconciling trade-offs between various solutions and technologies.
        - Finally, it’s about understanding the importance of business drivers and how they translate to architectural
        concerns

    In this chapter we explore these four aspects of thinking like an architect and seeing
    things with an architectural eye.

    1. Architecture Versus Design
        Thinking like an architect is knowing the difference
        between architecture and design and seeing how the two integrate closely to form sol‐
        utions to business and technical problems.

        As shown in the diagram, an architect is responsible for things like analyzing business requirements to extract
        and define the architectural characteristics (“-ilities”), selecting which architecture patterns and styles
        would fit the problem domain, and creating components (the building blocks of the
        system). The artifacts created from these activities are then handed off to the develop‐
        ment team, which is responsible for creating class diagrams for each component, cre‐
        ating user interface screens, and developing and testing source code.

        To make architecture work, both the physical and virtual barriers that exist between
        architects and developers must be broken down, thus forming a strong bidirectional
        relationship between architects and development teams. The architect and developer
        must be on the same virtual team to make this work, as depicted in Figure 2-2. Not
        only does this model facilitate strong bidirectional communication between architec‐
        ture and development, but it also allows the architect to provide mentoring and
        coaching to developers on the team.

            Dan: see diagram "2 traditional vs working architecture.jpg" to better understand this

        Unlike the old-school waterfall approaches to static and rigid software architecture,
        the architecture of today’s systems changes and evolves every iteration or phase of a
        project. A tight collaboration between the architect and the development team is
        essential for the success of any software project. So where does architecture end and
        design begin? It doesn’t. They are both part of the circle of life within a software
        project and must always be kept in synchronization with each other in order to
        succeed.

    2. Technical Breadth
        The scope of technological detail differs between developers and architects. Unlike a
        developer, who must have a significant amount of technical depth to perform their
        job, a software architect must have a significant amount of technical breadth to think
        like an architect and see things with an architecture point of view.

        As shown in Figure 2-3, any individual can partition all their knowledge into three
        sections: stuff you know (top of the pyramid), stuff you know you don’t know, (middle) and stuff you don’t know you
        don’t know (base of pyramid).

        A developer’s early career focuses on expanding the top of the pyramid, to build
        experience and expertise. This is the ideal focus early on, because developers need
        more perspective, working knowledge, and hands-on experience. Expanding the top
        incidentally expands the middle section; as developers encounter more technologies
        and related artifacts, it adds to their stock of stuff you know you don’t know.

        In Figure 2-4, expanding the top of the pyramid is beneficial because expertise is val‐
        ued. However, the stuff you know is also the stuff you must maintain—nothing is static
        in the software world. If a developer becomes an expert in Ruby on Rails, that exper‐
        tise won’t last if they ignore Ruby on Rails for a year or two. The things at the top of
        the pyramid require time investment to maintain expertise. Ultimately, the size of the
        top of an individual’s pyramid is their technical depth.

        However, the nature of knowledge changes as developers transition into the architect
        role. A large part of the value of an architect is a broad understanding of technology
        and how to use it to solve particular problems. For example, as an architect, it is more
        beneficial to know that five solutions exist for a particular problem than to have sin‐
        gular expertise in only one. The most important parts of the pyramid for architects
        are the top and middle sections; how far the middle section penetrates into the bot‐
        tom section represents an architect’s technical breadth

            Dan: see "2-5 technical dept breadth pyramid.jpg"
!!!
        As an architect, breadth is more important than depth. Because architects must make
        decisions that match capabilities to technical constraints, a broad understanding of a
        wide variety of solutions is valuable. Thus, for an architect, the wise course of action
        is to sacrifice some hard-won expertise and use that time to broaden their portfolio,
        as shown in Figure 2-6. As illustrated in the diagram, some areas of expertise will
        remain, probably in particularly enjoyable technology areas, while others usefully
        atrophy.

        Our knowledge pyramid illustrates how fundamentally different the role of architect
        compares to developer. Developers spend their whole careers honing expertise, and
        transitioning to the architect role means a shift in that perspective, which many indi‐
        viduals find difficult. This in turn leads to two common dysfunctions: first, an archi‐
        tect tries to maintain expertise in a wide variety of areas, succeeding in none of them
        and working themselves ragged in the process. Second, it manifests as stale expertise
        —the mistaken sensation that your outdated information is still cutting edge. We see
        this often in large companies where the developers who founded the company have
        moved into leadership roles yet still make technology decisions using ancient criteria

!!      Architects should focus on technical breadth so that they have a larger quiver from
        which to draw arrows. Developers transitioning to the architect role may have to
        change the way they view knowledge acquisition. Balancing their portfolio of knowl‐
        edge regarding depth versus breadth is something every developer should consider
        throughout their career.

    3. Analyzing Trade-Offs
        Thinking like an architect is all about seeing trade-offs in every solution, technical or
        otherwise, and analyzing those trade-offs to determine what is the best solution. To
        quote Mark (one of your authors):
            "Architecture is the stuff you can’t Google."

        Everything in architecture is a trade-off, which is why the famous answer to every
        architecture question in the universe is “it depends.” While many people get increas‐
        ingly annoyed at this answer, it is unfortunately true. You cannot Google the answer
        to whether REST or messaging would be better, or whether microservices is the right
        architecture style, because it does depend. It depends on the deployment environ‐
        ment, business drivers, company culture, budgets, timeframes, developer skill set, and
        dozens of other factors. Everyone’s environment, situation, and problem is different,
        hence why architecture is so hard. To quote Neal (another one of your authors):
            "There are no right or wrong answers in architecture—only trade-offs"

        Thinking architecturally is looking at the benefits of a given solution, but also analyz‐
        ing the negatives, or trade-offs, associated with a solution

    4. Understanding Business Drivers
        Thinking like an architect is understanding the business drivers that are required for
        the success of the system and translating those requirements into architecture charac‐
        teristics (such as scalability, performance, and availability).

    Balancing Architecture and Hands-On Coding
        One of the difficult tasks an architect faces is how to balance hands-on coding with
        software architecture. We firmly believe that every architect should code and be able
        to maintain a certain level of technical depth.
        While this may seem like an easy task, it is sometimes rather difficult to accomplish.

        The first tip in striving for a balance between hands-on coding and being a software
        architect is avoiding the bottleneck trap. The bottleneck trap occurs when the archi‐
        tect has taken ownership of code within the critical path of a project (usually the
        underlying framework code) and becomes a bottleneck to the team.
        One way to avoid the bottleneck trap as an effective software architect is to delegate
        the critical path and framework code to others on the development team and then
        focus on coding a piece of business functionality (a service or a screen) one to three
        iterations down the road

        How can a software architect still remain hands-on and maintain some level of technical depth?
            The first way is to do frequent proof-of-concepts or POCs. This practice not only
            requires the architect to write source code, but it also helps validate an architecture
            decision by taking the implementation details into account. For example, if an archi‐
            tect is stuck trying to make a decision between two caching solutions, one effective
            way to help make this decision is to develop a working example in each caching prod‐
            uct and compare the results.

            Another way an architect can remain hands-on is to tackle some of the technical debt
            stories or architecture stories, freeing the development team up to work on the criti‐
            cal functional user stories.

            Similarly, working on bug fixes within an iteration is another way of maintaining
            hands-on coding while helping the development team as well.

            Leveraging automation by creating simple command-line tools and analyzers to help
            the development team with their day-to-day tasks is another great way to maintain
            hands-on coding skills while making the development team more effective. Look for
            repetitive tasks the development team performs and automate the process.
            Automation can also be in the form of architectural analysis and fitness functions to
            ensure the vitality and compliance of the architecture. For example, an architect can
            write Java code in ArchUnit in the Java platform to automate architectural compli‐
            ance, or write custom fitness functions to ensure architectural compliance while gain‐
            ing hands-on experience

            A final technique to remain hands-on as an architect is to do frequent code reviews.
            While the architect is not actually writing code, at least they are involved in the source code.


========================================================================================================================
Chapter 3. Modularity
    Different platforms offer different reuse mechanisms for code, but all support some
    way of grouping related code together into modules. While this concept is universal in
    software architecture, it has proven slippery to define. A casual internet search yields
    dozens of definitions, with no consistency (and some contradictions)

    Understanding modularity and its many incarnations in the development platform of
    choice is critical for architects. Many of the tools we have to analyze architecture
    (such as metrics, fitness functions, and visualizations) rely on these modularity con‐
    cepts.

    Definition
        We use modularity to
        describe a logical grouping of related code, which could be a group of classes in an
        object-oriented language or functions in a structured or functional language. Most
        languages provide mechanisms for modularity (package in Java, namespace in .NET,
        and so on). Developers typically use modules as a way to group related code together.
        For example, the com.mycompany.customer package in Java should contain things
        related to customers.

!!!     For discussions about architecture, we use modularity as a general term to denote a
        related grouping of code: classes, functions, or any other grouping. This doesn’t imply
        a physical separation, merely a logical one; the difference is sometimes important. For
        example, lumping a large number of classes together in a monolithic application may
        make sense from a convenience standpoint. However, when it comes time to restruc‐
        ture the architecture, the coupling encouraged by loose partitioning becomes an
        impediment to breaking the monolith apart. Thus, it is useful to talk about modular‐
        ity as a concept separate from the physical separation forced or implied by a particu‐
        lar platform.

!!!     Sometimes the module structure is reflected physically.
        For example, Java requires that its package structure must reflect the directory struc‐
        ture of the physical class files.

!!!!!!  A Language with No Name Conflicts: Java 1.0
            The original designers of Java had extensive experience dealing with name conflicts
            and clashes in the various programming platforms at the time. The original design of
            Java used a clever hack to avoid the possibility of ambiguity between two classes that
            had the same name. For example, what if your problem domain included a catalog
            order and an installation order: both named order but with very different connota‐
            tions (and classes). The solution in Java was to create the package namespace mecha‐
            nism, along with the requirement that the physical directory structure just match the
            package name. Because filesystems won’t allow the same named file to reside in the
            same directory, they leveraged the inherent features of the operating system to avoid
            the possibility of ambiguity. Thus, the original classpath in Java contained only
            directories, disallowing the possibility of name conflicts.
            However, as the language designers discovered, forcing every project to have a fully
            formed directory structure was cumbersome, especially as projects became larger.
            Plus, building reusable assets was difficult: frameworks and libraries must be “explo‐
            ded” into the directory structure. In the second major release of Java (1.2, called Java
            2), designers added the jar mechanism, allowing an archive file to act as a directory
            structure on a classpath. For the next decade, Java developers struggled with getting
            the classpath exactly right, as a combination of directories and JAR files. And, of
            course, the original intent was broken: now two JAR files could create conflicting
            names on a classpath, leading to numerous war stories of debugging class loaders.

    Measuring Modularity
        Given the importance of modularity to architects, they need tools to understand it.
        Fortunately, researchers created a variety of language-agnostic metrics to help archi‐
        tects understand modularity. We focus on three key concepts: cohesion, coupling, and
        connascence.

        1.Cohesion
            Cohesion refers to what extent the parts of a module should be contained within the
            same module. In other words, it is a measure of how related the parts are to one
            another. Ideally, a cohesive module is one where all the parts should be packaged
            together, because breaking them into smaller pieces would require coupling the parts
            together via calls between modules to achieve useful results.

            For example, consider this module definition:
                Customer Maintenance
                    • add customer
                    • update customer
                    • get customer
                    • notify customer
                    • get customer orders
                    • cancel customer orders
            Should the last two entries reside in this module or should the developer create two
            separate modules, such as:
                Customer Maintenance
                    • add customer
                    • update customer
                    • get customer
                    • notify customer

                Order Maintenance
                    • get customer orders
                    • cancel customer orders
!!!         Which is the correct structure? As always, it depends:
                • Are those the only two operations for Order Maintenance? If so, it may make
                sense to collapse those operations back into Customer Maintenance.
                • Is Customer Maintenance expected to grow much larger, encouraging developers
                to look for opportunities to extract behavior?
                • Does Order Maintenance require so much knowledge of Customer information
                that separating the two modules would require a high degree of coupling to make
                it functional?

            These questions represent the kind of trade-off analysis at the heart of the job of a
            software architect.

!!!         The Chidamber and Kemerer Lack of Cohesion in Methods (LCOM) metric meas‐
            ures the structural cohesion of a module, typically a component.
            LCOM = The sum of sets of methods not shared via sharing fields

            Consider a class with private fields a and b. Many of the methods only access a, and
            many other methods only access b. The sum of the sets of methods not shared via
            sharing fields (a and b) is high; therefore, this class reports a high LCOM score, indi‐
            cating that it scores high in lack of cohesion in methods.

                Dan: see pic for a very good explanation "3-1 LCOM cohesion metric.png"

            The LCOM metric is useful to architects who are analyzing code bases in order to
            move from one architectural style to another. One of the common headaches when
            moving architectures are shared utility classes. Using the LCOM metric can help
            architects find classes that are incidentally coupled and should never have been a sin‐
            gle class to begin with.
!!!         Many software metrics have serious deficiencies, and LCOM is not immune. All this
            metric can find is structural lack of cohesion; it has no way to determine logically if
            particular pieces fit together


        2.Coupling
            Fortunately, we have better tools to analyze coupling in code bases, based in part on
            graph theory
!!            Afferent coupling measures the number of incoming
            connections to a code artifact (component, class, function, and so on).
!!            Efferent coupling measures the outgoing connections to other code artifacts. For virtually every
            platform tools exist that allow architects to analyze the coupling characteristics of
            code in order to assist in restructuring, migrating, or understanding a code base.

            Borrowing concepts from mathematics, they coined the now-common afferent and efferent
            coupling terms, which should have been called incoming and outgoing coupling.
            However, because the original authors leaned toward mathematical symmetry rather
            than clarity, developers came up with several mnemonics to help out: a appears
            before e in the English alphabet, corresponding to incoming being before outgoing, or
            the observation that the letter e in efferent matches the initial letter in exit, corresponding
            to outgoing connections.

        3.Abstractness, Instability, and Distance from the Main Sequence
            These metrics were created by Robert Martin for a C++ book, but are widely applicable to other
            object-oriented languages

!!!         Abstractness is the ratio of abstract artifacts (abstract classes, interfaces, and so on) to
            concrete artifacts (implementation). It represents a measure of abstractness versus
            implementation. For example, consider a code base with no abstractions, just a huge,
            single function of code (as in a single main() method). The flip side is a code base
            with too many abstractions, making it difficult for developers to understand how
            things wire together (for example, it takes developers a while to figure out what to do
            with an AbstractSingletonProxyFactoryBean).

!!          Architects calculate abstractness by calculating the ratio of the sum of abstract arti‐
            facts to the sum of the concrete ones.
            The easiest way to visualize this metric: consider an appli‐
            cation with 5,000 lines of code, all in one main() method. The abstractness numera‐
            tor is 1, while the denominator is 5,000, yielding an abstractness of almost 0. Thus,
            this metric measures the ratio of abstractions in your code.

            Instability, is defined as the ratio of efferent coupling to the
            sum of both efferent and afferent coupling

                Instability = Ce / ( Ce + Ca)
            In the equation, ce represents efferent (or outgoing) coupling, and ca represents affer‐
            ent (or incoming) coupling

!!!         The instability metric determines the volatility of a code base. A code base that exhib‐
            its high degrees of instability breaks more easily when changed because of high cou‐
            pling. For example, if a class calls to many other classes to delegate work, the calling
            class shows high susceptibility to breakage if one or more of the called methods
            change.

        4. Distance from the Main Sequence
            One of the few holistic metrics architects have for architectural structure is distance
            from the main sequence, a derived metric based on instability and abstractness, shown

            Distance from the Main Sequence = A + I − 1
            In the equation, A = abstractness and I = instability

            The distance metric imagines an ideal relationship between abstractness and instability;
            classes that fall near this idealized line exhibit a healthy mixture of these two com‐
            peting concerns.
                Dan: check "3-3 distance from main sequence"

!!!         developers graph the candidate class, then measure the distance from
            the idealized line. The closer to the line, the better balanced the class. Classes that fall
            too far into the upper-righthand corner enter into what architects call the zone of use‐
            lessness: code that is too abstract becomes difficult to use. Conversely, code that falls
            into the lower-lefthand corner enter the zone of pain: code with too much implemen‐
            tation and not enough abstraction becomes brittle and hard to maintain,

            Tools exist in many platforms to provide these measures, which assist architects when
            analyzing code bases because of unfamiliarity, migration, or technical debt
            assessment.

        5. Connascence
            Here’s how he defined the term:
!!!!            Two components are connascent if a change in one would require the other to be
                modified in order to maintain the overall correctness of the system.

            He developed two types of connascence: static and dynamic.

            Static connascence
                Static connascence refers to source-code-level coupling (as opposed to execution-time
                coupling, covered in “Dynamic connascence”)

                Connascence of Name (CoN)
                    Multiple components must agree on the name of an entity.
                    Names of methods represents the most common way that code bases are coupled
                    and the most desirable, especially in light of modern refactoring tools that make
                    system-wide name changes trivial.

                Connascence of Type (CoT)
                    Multiple components must agree on the type of an entity.
                    This type of connascence refers to the common facility in many statically typed
                    languages to limit variables and parameters to specific types

                Connascence of Meaning (CoM) or Connascence of Convention (CoC)
                    Multiple components must agree on the meaning of particular values.
                    The most common obvious case for this type of connascence in code bases is
                    hard-coded numbers rather than constants. For example, it is common in some
                    languages to consider defining somewhere int TRUE = 1; int FALSE = 0.
                    Imagine the problems if someone flips those values.

                Connascence of Position (CoP)
                    Multiple components must agree on the order of values.
                    This is an issue with parameter values for method and function calls even in lan‐
                    guages that feature static typing. For example, if a developer creates a method
                    void updateSeat(String name, String seatLocation) and calls it with the
                    values updateSeat("14D", "Ford, N"), the semantics aren’t correct even if the
                    types are.

                Connascence of Algorithm (CoA)
                    Multiple components must agree on a particular algorithm.
                    A common case for this type of connascence occurs when a developer defines a
                    security hashing algorithm that must run on both the server and client and pro‐
                    duce identical results to authenticate the user. Obviously, this represents a high
                    form of coupling—if either algorithm changes any details, the handshake will no
                    longer work.

            Dynamic connascence
                The other type of connascence Page-Jones defined was dynamic connascence, which
                analyzes calls at runtime.

                Connascence of Execution (CoE)
                    The order of execution of multiple components is important.
                    Consider this code:
                    email = new Email();
                    email.setRecipient("foo@example.com");
                    email.setSender("me@me.com");
                    email.send();
                    email.setSubject("whoops");
                    It won’t work correctly because certain properties must be set in order.

                Connascence of Timing (CoT)
                    The timing of the execution of multiple components is important.
                    The common case for this type of connascence is a race condition caused by two
                    threads executing at the same time, affecting the outcome of the joint operation

                Connascence of Values (CoV)
                    Occurs when several values relate on one another and must change together.
                    Consider the case where a developer has defined a rectangle as four points, repre‐
                    senting the corners. To maintain the integrity of the data structure, the developer
                    cannot randomly change one of points without considering the impact on the
                    other points.
                    The more common and problematic case involves transactions, especially in dis‐
                    tributed systems. When an architect designs a system with separate databases, yet
                    needs to update a single value across all of the databases, all the values must
                    change together or not at all.

                Connascence of Identity (CoI)
                    Occurs when multiple components must reference the same entity

                Architects have a harder time determining dynamic connascence because we lack
                tools to analyze runtime calls as effectively as we can analyze the call graph.

            Strength
                Architects determine the strength of connascence by the ease with which a devel‐
                oper can refactor that type of coupling; different types of connascence are
                demonstrably more desirable, as shown in Figure 3-5. Architects and developers
                can improve the coupling characteristics of their code base by refactoring toward
                better types of connascence.

                    Dan: check out "3-5 Strength of connesance"

!!!!        Page-Jones offers three guidelines for using connascence to improve systems
            modularity:
                1. Minimize overall connascence by breaking the system into encapsulated elements
                2. Minimize any remaining connascence that crosses encapsulation boundaries
                3. Maximize the connascence within encapsulation boundaries


========================================================================================================================
Chapter 4. Architecture Characteristics Defined

    Architects may collaborate on defining the domain or business requirements, but one
    key responsibility entails defining, discovering, and otherwise analyzing all the things
    the software must do that isn’t directly related to the domain functionality: architec‐
    tural characteristics.
        example: Performance, Security, Scalability, Auditability etc

    Many organizations describe these features of software with a variety of terms, including nonfunc‐
    tional requirements, but we dislike that term because it is self-denigrating. Architects
    created that term to distinguish architecture characteristics from functional require‐
    ments, but naming something nonfunctional has a negative impact from a language
    standpoint: how can teams be convinced to pay enough attention to something “nonfunctional”?

    We prefer architecture characteristics because it describes concerns critical to the success of the architecture,
    and therefore the system as a whole, without discounting its importance.

!!! An architecture characteristic meets three criteria:
        • Specifies a nondomain design consideration
            When designing an application, the requirements specify what the application
            should do; architecture characteristics specify operational and design criteria for
            success, concerning how to implement the requirements and why certain choices
            were made. For example, a common important architecture characteristic speci‐
            fies a certain level of performance for the application, which often doesn’t appear
            in a requirements document
        • Influences some structural aspect of the design
            The primary reason architects try to describe architecture characteristics on
            projects concerns design considerations: does this architecture characteristic
            require special structural consideration to succeed? For example, security is a
            concern in virtually every project, and all systems must take a baseline of precau‐
            tions during design and coding. However, it rises to the level of architecture char‐
            acteristic when the architect needs to design something special. Consider two
            cases surrounding payment in a example system:
                Third-party payment processor
                    If an integration point handles payment details, then the architecture
                    shouldn’t require special structural considerations. The design should incor‐
                    porate standard security hygiene, such as encryption and hashing, but
                    doesn’t require special structure.
                In-application payment processing
                    If the application under design must handle payment processing, the archi‐
                    tect may design a specific module, component, or service for that purpose to
                    isolate the critical security concerns structurally. Now, the architecture char‐
                    acteristic has an impact on both architecture and design.
        • Is critical or important to application success
!!!!        Applications could support a huge number of architecture characteristics…but
            shouldn’t. Support for each architecture characteristic adds complexity to the
            design. Thus, a critical job for architects lies in choosing the fewest architecture
            characteristics rather than the most possible.

!!
    We further subdivide architecture characteristics into implicit versus explicit architecture
    characteristics. Implicit ones rarely appear in requirements, yet they’re necessary
    for project success. For example, availability, reliability, and security underpin
    virtually all applications, yet they’re rarely specified in design documents. Architects
    must use their knowledge of the problem domain to uncover these architecture characteristics
    during the analysis phase.

    Operational Architecture Characteristics
        Operational architecture characteristics cover capabilities such as performance, scala‐
        bility, elasticity, availability, and reliability

    Structural Architecture Characteristics
        Architects must concern themselves with code structure. In many cases, the architect
        has sole or shared responsibility for code quality concerns, such as good modularity,
        controlled coupling between components, readable code, and a host of other internal
        quality assessments

        Configurability     Ability for the end users to easily change aspects of the software’s configuration (through usable
                            interfaces).
        Extensibility       How important it is to plug new pieces of functionality in.
        Installability      Ease of system installation on all necessary platforms.
        Leverageability/    Ability to leverage common components across multiple products.
        reuse

        Localization        Support for multiple languages on entry/query screens in data fields; on reports, multibyte character
                            requirements and units of measure or currencies.
        Maintainability     How easy it is to apply changes and enhance the system?
        Portability         Does the system need to run on more than one platform?
        Supportability      What level of technical support is needed by the application? What level of logging and other facilities
                            are required to debug errors in the system?
        Upgradeability      Ability to easily/quickly upgrade from a previous version of this application/solution to a newer version
                            on servers and clients.

    Cross-Cutting Architecture Characteristics
        While many architecture characteristics fall into easily recognizable categories, many
        fall outside or defy categorization yet form important design constraints and consid‐
        erations.
            Accessibility   Access to all your users, including those with disabilities like colorblindness or hearing loss.
            Archivability   Will the data need to be archived or deleted after a period of time?
            Authentication  Security requirements to ensure users are who they say they are.
            Authorization   Security requirements to ensure users can access only certain functions within the application (by use case,
                            subsystem, webpage, business rule, field level, etc.).
            Legal           What legislative constraints is the system operating in (data protection, Sarbanes Oxley, GDPR, etc.)? What
                            reservation rights does the company require? Any regulations regarding the way the application is to be
                            built or deployed?
            Privacy         Ability to hide transactions from internal company employees (encrypted transactions so even DBAs and
                            network architects cannot see them).
            Security        Does the data need to be encrypted in the database? Encrypted for network communication between
                            internal systems? What type of authentication needs to be in place for remote user access?
            Supportability  What level of technical support is needed by the application? What level of logging and other facilities are
                            required to debug errors in the system?
            Usability/      Level of training required for users to achieve their goals with the application/solution
            achievability

    Trade-Offs and Least Worst Architecture
        Applications can only support a few of the architecture characteristics we’ve listed for
        a variety of reasons. First, each of the supported characteristics requires design effort
        and perhaps structural support. Second, the bigger problem lies with the fact that
        each architecture characteristic often has an impact on others. For example, if an
        architect wants to improve security, it will almost certainly negatively impact perfor‐
        mance: the application must do more on-the-fly encryption, indirection for secrets
        hiding, and other activities that potentially degrade performance.

!!!!!!  Never shoot for the best architecture, but rather the least worst architecture.


========================================================================================================================
Chapter 5. Identifying Architectural Characteristics

    Identifying the driving architectural characteristics is one of the first steps in creating
    an architecture or determining the validity of an existing architecture. Identifying the
    correct architectural characteristics (“-ilities”) for a given problem or application
    requires an architect to not only understand the domain problem, but also collabo‐
    rate with the problem domain stakeholders to determine what is truly important
    from a domain perspective.

    Extracting Architecture Characteristics from Domain Concerns

        An architect must be able to translate domain concerns to identify the right architec‐
        tural characteristics. For example, is scalability the most important concern, or is it
        fault tolerance, security, or performance? Perhaps the system requires all four charac‐
        teristics combined.

!!!     One tip when collaborating with domain stakeholders to define the driving architec‐
        ture characteristics is to work hard to keep the final list as short as possible. A com‐
        mon anti-pattern in architecture entails trying to design a generic architecture, one
        that supports all the architecture characteristics. Each architecture characteristic the
        architecture supports complicates the overall system design; supporting too many
        architecture characteristics leads to greater and greater complexity before the archi‐
        tect and developers have even started addressing the problem domain

        A better approach is to have the domain stakeholders select the top three most
        important characteristics from the final list (in any order). Not only is this much eas‐
        ier to gain consensus on, but it also fosters discussions about what is most important
        and helps the architect analyze trade-offs when making vital architecture decisions

        Table 5-1. Translation of domain concerns to architecture characteristics
        (aka management/stakeholder concerns translated to architecture language)
        Domain concern                  Architecture characteristics
        Mergers and acquisitions        Interoperability, scalability, adaptability, extensibility
        Time to market                  Agility, testability, deployability
        User satisfaction               Performance, availability, fault tolerance, testability, deployability, agility, security
        Competitive advantage           Agility, testability, deployability, scalability, availability, fault tolerance
        Time and budget                 Simplicity, feasibility

    Extracting Architecture Characteristics from Requirements

        For example, suppose an architect designs an application that
        handles class registration for university students. To make the math easy, assume that
        the school has 1,000 students and 10 hours for registration. Should an architect
        design a system assuming consistent scale, making the implicit assumption that the
        students during the registration process will distribute themselves evenly over time?
        Or, based on knowledge of university students habits and proclivities, should the
        architect design a system that can handle all 1,000 students attempting to register in
        the last 10 minutes?

        The Origin of Architecture Katas
            So how are we supposed to get great architects if they only get the chance to architect
            fewer than a half dozen times in their career?
            To provide a curriculum for aspiring architects, Ted created the first architecture
            katas site, which your authors Neal and Mark adapted and updated. The basic prem‐
            ise of the kata exercise provides architects with a problem stated in domain terms and
            additional context (things that might not appear in requirements yet impact design).
            Small teams work for 45 minutes on a design, then show results to the other groups,
            who vote on who came up with the best architecture. True to its original purpose,
            architecture katas provide a useful laboratory for aspiring architects.

        First, separate the candidate architecture characteristics into explicit and implicit
        characteristics.

        Explicit Characteristics
            Explicit architecture characteristics appear in a requirements specification as part of
            the necessary design. For example, a shopping website may aspire to support a partic‐
            ular number of concurrent users, which domain analysts specify in the requirements.
            An architect should consider each part of the requirements to see if it contributes to
            an architecture characteristic.

!!!         an architect should consider domain-level predictions about expected metrics, as represented
            in the Users section of the kata.

!!          Notice that the problem statement didn’t explicitly ask for scalability, but rather
            expressed that requirement as an expected number of users. Architects must often
            decode domain language into engineering equivalents.

        Implicit Characteristics
            Many architecture characteristics aren’t specified in requirements documents, yet
            they make up an important aspect of the design. One implicit architecture character‐
            istic the system might want to support is availability: making sure users can access the
            sandwich site. Closely related to availability is reliability: making sure the site stays up
            during interactions—no one wants to purchase from a site that continues dropping
            connections, forcing them to log in again.
            Security appears as an implicit characteristic in every system: no one wants to create
            insecure software.


        It is important to note that there are no correct answers in choosing architecture characteristics,
        only incorrect ones (or, as Mark notes in one of his well-known quotes):
!!!         There are no wrong answers in architecture, only expensive ones

!!!     No architecture decision should be made isolated from the implementation team (which
        leads to the dreaded Ivory Tower Architect anti-pattern)

!      A useful exercise once the team has made a first pass at identifying the architecture characteristics is
       to try to determine the least important one—if you must eliminate one, which would it be?


========================================================================================================================
Chapter 6. Measuring and Governing Architecture Characteristics

    Architects must deal with the extraordinarily wide variety of architecture characteris‐
    tics across all different aspects of software projects. Operational aspects like perfor‐
    mance, elasticity, and scalability comingle with structural concerns such as
    modularity and deployability. This chapter focuses on concretely defining some of
    the more common architecture characteristics and building governance mechanisms
    for them.

    Measuring Architecture Characteristics
        Operational Measures
            Many architecture characteristics have obvious direct measurements, such as perfor‐
            mance or scalability. However, even these offer many nuanced interpretations,
            depending on the team’s goals. For example, perhaps a team measures the average
            response time for certain requests, a good example of an operational architecture
            characteristics measure. But if teams only measure the average, what happens if some
            boundary condition causes 1% of requests to take 10 times longer than others? If the
            site has enough traffic, the outliers may not even show up. Therefore, a team may also
            want to measure the maximum response times to catch outliers.

        Structural Measures
            Some objective measures are not so obvious as performance. What about internal
            structural characteristics, such as well-defined modularity? Unfortunately, compre‐
            hensive metrics for internal code quality don’t yet exist. However, some metrics and
            common tools do allow architects to address some critical aspects of code structure,
            albeit along narrow dimensions.

            An obvious measurable aspect of code is complexity, defined by the cyclomatic complexity metric.
            Cyclomatic Complexity (CC) is a code-level metric designed to provide an object
            measure for the complexity of code, at the function/method, class, or application
            level, developed by Thomas McCabe, Sr., in 1976.
            It is computed by applying graph theory to code, specifically decision points, which
            cause different execution paths. For example, if a function has no decision statements
            (such as if statements), then CC = 1. If the function had a single conditional, then CC
            = 2 because two possible execution paths exist.
            The formula for calculating the CC for a single function or method is CC = E − N + 2,
            where N represents nodes (lines of code), and E represents edges (possible decisions).

            What’s a Good Value for Cyclomatic Complexity?
                A common question the authors receive when talking about this subject is: what’s a
                good threshold value for CC? Of course, like all answers in software architecture: it
                depends! It depends on the complexity of the problem domain. For example, if you
                have an algorithmically complex problem, the solution will yield complex functions.
                Some of the key aspects of CC for architects to monitor: are functions complex
                because of the problem domain or because of poor coding? Alternatively, is the code
                partitioned poorly? In other words, could a large method be broken down into
                smaller, logical chunks, distributing the work (and complexity) into more wellfactored methods?
                In general, the industry thresholds for CC suggest that a value under 10 is acceptable,
                barring other considerations such as complex domains. We consider that threshold
                very high and would prefer code to fall under five, indicating cohesive, well-factored
                code.

        Process Measures
            Some architecture characteristics intersect with software development processes.

            Testability is measurable through code coverage tools for virtually all platforms that
            assess the completeness of testing. Like all software checks, it cannot replace thinking
            and intent. For example, a code base can have 100% code coverage yet poor assertions
            that don’t actually provide confidence in code correctness. However, testability is
            clearly an objectively measurable characteristic

            Deployability can be measured via a variety of metrics: percentage of successful to failed deployments,
            how long deployments take, issues/bugs raised by deployments, and a host of others.

    Governance and Fitness Functions
        Governing Architecture Characteristics
            The book Building Evolutionary Architectures (O’Reilly)
            describes a family of techniques, called fitness functions, used to automate many
            aspects of architecture governance

            Fitness Functions
!!!             The word “evolutionary” in Building Evolutionary Architectures comes more from
                evolutionary computing than biology. One of the authors, Dr. Rebecca Parsons, spent
                some time in the evolutionary computing space, including tools like genetic algo‐
                rithms. A genetic algorithm executes and produces an answer and then undergoes
                mutation by well-known techniques defined within the evolutionary computing
                world. If a developer tries to design a genetic algorithm to produce some beneficial
                outcome, they often want to guide the algorithm, providing an objective measure
                indicating the quality of the outcome. That guidance mechanism is called a tness
                function: an object function used to assess how close the output comes to achieving
                the aim. For example, suppose a developer needed to solve the traveling salesperson
                problem, a famous problem used as a basis for machine learning. Given a salesperson
                and a list of cities they must visit, with distances between them, what is the optimum
                route? If a developer designs a genetic algorithm to solve this problem, one fitness
                function might evaluate the length of the route, as the shortest possible one repre‐
                sents highest success. Another fitness function might be to evaluate the overall cost
                associated with the route and attempt to keep cost at a minimum. Yet another might
                be to evaluate the time the traveling salesperson is away and optimize to shorten the
                total travel time.

                Architecture fitness function
                    Any mechanism that provides an objective integrity assessment of some architec‐
                    ture characteristic or combination of architecture characteristics

                Here are a couple of examples of fitness functions that test various aspects of modularity.

!!                  Cyclic dependencies
                        Modularity is an implicit architecture characteristic that most architects care about,
                        because poorly maintained modularity harms the structure of a code base; thus,
                        architects should place a high priority on maintaining good modularity. However,
                        forces work against the architect’s good intentions on many platforms. For example,
                        when coding in any popular Java or .NET development environment, as soon as a
                        developer references a class not already imported, the IDE helpfully presents a dialog
                        asking the developers if they would like to auto-import the reference. This occurs so
                        often that most programmers develop the habit of swatting the auto-import dialog
                        away like a reflex action. However, arbitrarily importing classes or components
                        between one another spells disaster for modularity

                        Having a network of components such as this damages modularity because a developer cannot reuse a
                        single component without also bringing the others along. And, of course, if the other
                        components are coupled to other components, the architecture tends more and more
                        toward the Big Ball of Mud anti-pattern.

!!!!!                   If an architect allows a development team to rampantly import across the code base for a week
                        until the code review, serious damage has already occurred in the code base.
                        The solution to this problem is to write a fitness function to look after cycles, as
                        shown in Example 6-2.

                        In the code, an architect uses the metrics tool JDepend to check the dependencies
                        between packages. The tool understands the structure of Java packages and fails the
                        test if any cycles exist. An architect can wire this test into the continuous build on a
                        project and stop worrying about the accidental introduction of cycles by trigger happy
                        developers. This is a great example of a fitness function guarding the impor‐
                        tant rather than urgent practices of software development: it’s an important concern
                        for architects yet has little impact on day-to-day coding

                    Distance from the main sequence fitness function
                        In “Coupling” on page 44, we introduced the more esoteric metric of distance from
                        the main sequence, which architects can also verify using fitness functions, as shown
                        in Example 6-3.

!!!                 The sophistication of fitness function tools has increased over the last few years,
                    including some special purpose tools. One such tool is ArchUnit, a Java testing
                    framework inspired by and using several parts of the JUnit ecosystem. ArchUnit pro‐
                    vides a variety of predefined governance rules codified as unit tests and allows archi‐
                    tects to write specific tests that address modularity.

                    However, how can the architect
                    ensure that developers will respect those layers? Some developers may not under‐
                    stand the importance of the patterns, while others may adopt a “better to ask forgive‐
                    ness than permission” attitude because of some overriding local concern such as
                    performance. But allowing implementers to erode the reasons for the architecture
                    hurts the long-term health of the architecture.

!!!                 Example 6-4. ArchUnit fitness function to govern layers
                        layeredArchitecture()
                             .layer("Controller").definedBy("..controller..")
                             .layer("Service").definedBy("..service..")
                             .layer("Persistence").definedBy("..persistence..")
                             .whereLayer("Controller").mayNotBeAccessedByAnyLayer()
                             .whereLayer("Service").mayOnlyBeAccessedByLayers("Controller")
                             .whereLayer("Persistence").mayOnlyBeAccessedByLayers("Service")

!!!                 Another example of fitness functions is Netflix’s Chaos Monkey and the attendant
                    Simian Army. In particular, the Conformity, Security, and Janitor Monkeys exemplify
                    this approach. The Conformity Monkey allows Netflix architects to define gover‐
                    nance rules enforced by the monkey in production. For example, if the architects
                    decided that each service should respond usefully to all RESTful verbs, they build that
                    check into the Conformity Monkey. Similarly, the Security Monkey checks each ser‐
                    vice for well-known security defects, like ports that shouldn’t be active and configura‐
                    tion errors. Finally, the Janitor Monkey looks for instances that no other services
                    route to anymore. Netflix has an evolutionary architecture, so developers routinely
                    migrate to newer services, leaving old services running with no collaborators. Because
                    services running on the cloud consume money, the Janitor Monkey looks for orphan
                    services and disintegrates them out of production

                    Dan: https://github.com/netflix/chaosmonkey

!!                  A few years ago, the influential book The Checklist Manifesto by Atul Gawande (Pica‐
                    dor) described how professions such as airline pilots and surgeons use checklists
                    (sometimes legally mandated). It’s not because those professionals don’t know their
                    jobs or are forgetful. Rather, when professionals do a highly detailed job over and
                    over, it becomes easy for details to slip by; a succinct checklist forms an effective
                    reminder. This is the correct perspective on fitness functions—rather than a heavy‐
                    weight governance mechanism, fitness functions provide a mechanism for architects
                    to express important architectural principles and automatically verify them


========================================================================================================================
Chapter 7. Scope of Architecture Characteristics

!!  A prevailing axiomatic assumption in the software architecture world had tradition‐
    ally placed the scope of architecture characteristics at the system level. For example,
    when architects talk about scalability, they generally couch that discussion around the
    scalability of the entire system. That was a safe assumption a decade ago, when virtu‐
    ally all systems were monolithic. With the advent of modern engineering techniques
    and the architecture styles they enabled, such as microservices, the scope of architec‐
    ture characteristics has narrowed considerably

    no matter how much an architect puts
    effort into designing a performant or elastic code base, if the system uses a database
    that doesn’t match those characteristics, the application won’t be successful.

    When evaluating many operational architecture characteristics, an architect must
    consider dependent components outside the code base that will impact those charac‐
    teristics. Thus, architects need another method to measure these kinds of dependencies
!!  That lead the Building Evolutionary Architectures authors to define the term
    architecture quantum.

!!! To define the architecture quantum, we  needed a measure of how components are “wired” together
    which corresponds to the connascence concept. For example, if two services in a microservices architecture
    share the same class definition of some class, like address, we say they are statically
    connascent with each other—changing the shared class requires changes to both services.

!!  For dynamic connascence, we define two types: synchronous and asynchronous. Syn‐
    chronous calls between two distributed services have the caller wait for the response
    from the callee. On the other hand, asynchronous calls allow fire-and-forget semantics
    in event-driven architectures, allowing two different services to differ in operational architecture

    Architectural Quanta and Granularity

!!!!    Architecture quantum = An independently deployable artifact with high functional cohesion and synchronous connascence

!!!!    Independently deployable
            An architecture quantum includes all the necessary components to function
            independently from other parts of the architecture. For example, if an application
            uses a database, it is part of the quantum because the system won’t function
            without it. This requirement means that virtually all legacy systems deployed
            using a single database by definition form a quantum of one. However, in the
            microservices architecture style, each service includes its own database (part of
            the bounded context driving philosophy in microservices

!!!!    High functional cohesion
            Cohesion in component design refers to how well the contained code is unified in
            purpose. For example, a Customer component with properties and methods all
            pertaining to a Customer entity exhibits high cohesion; whereas a Utility com‐
            ponent with a random collection of miscellaneous methods would not.
            High functional cohesion implies that an architecture quantum does something
            purposeful. This distinction matters little in traditional monolithic applications
            with a single database. However, in microservices architectures, developers typi‐
            cally design each service to match a single workflow
            thus exhibiting high functional cohesion.

        Synchronous connascence
            Synchronous connascence implies synchronous calls within an application context
            or between distributed services that form this architecture quantum. For exam‐
            ple, if one service in a microservices architecture calls another one synchronously
            , each service cannot exhibit extreme differences in operational
            architecture characteristics. If the caller is much more scalable than the callee,
            timeouts and other reliability concerns will occur. Thus, synchronous calls create
            dynamic connascence for the length of the call—if one is waiting for the other,
            their operational architecture characteristics must be the same for the duration of the call.

!!!!!   The architecture quantum concept provides the new scope for architecture characteristics.
        In modern systems, architects define architecture characteristics at the quan‐
        tum level rather than system level. By looking at a narrower scope for important
        operational concerns, architects may identify architectural challenges early, leading to
        hybrid architectures.


========================================================================================================================
Chapter 8. Component-Based Thinking

    In Chapter 3, we discussed modules as a collection of related code. However, archi‐
    tects typically think in terms of components, the physical manifestation of a module.
    Developers physically package modules in different ways, sometimes depending on
    their development platform. We call physical packaging of modules components. Most
    languages support physical packaging as well: jar files in Java, dll in .NET, gem in
    Ruby, and so on. In this chapter, we discuss architectural considerations around com‐
    ponents, ranging from scope to discovery.

    Component Scope
        the simplest component wraps code at a higher level of modularity than classes (or functions, in nonobjectoriented
        languages). This simple wrapper is often called a library, which tends to run in the same memory address as the
        calling code and communicate via language function call mechanisms.

        Components also appear as subsystems or layers in architecture, as the deployable
        unit of work for many event processors.
!!!!    Another type of component, a service, tends to run in its own address space and communicates via low-level
        networking protocols like TCP/IP or higher-level formats like REST or message queues, forming standalone,
        deployable units in architectures like microservices

            Dan: check out "8-1 different types of components"

    Architect Role
        Typically, the architect defines, refines, manages, and governs components within an
        architecture. Software architects, in collaboration with business analysts, subject mat‐
        ter experts, developers, QA engineers, operations, and enterprise architects, create the
        initial design for software, incorporating the architecture characteristics discussed in
        Chapter 4 and the requirements for the software system.

!!!        Generally the component is the lowest level of the software system an architect inter‐
        acts directly with, with the exception of many of the code quality metrics discussed in
        Chapter 6 that affect code bases holistically. Components consist of classes or func‐
        tions (depending on the implementation platform), whose design falls under the
        responsibility of tech leads or developers. It’s not that architects shouldn’t involve
        themselves in class design (particularly when discovering or applying design pat‐
        terns), but they should avoid micromanaging each decision from top to bottom in the system.

        An architect must identify components as one of the first tasks on a new project. But
        before an architect can identify components, they must know how to partition the architecture.

        Architecture Partitioning
            The First Law of Software Architecture states that everything in software is a tradeoff, including how
            architects create components in an architecture. Because components represent a general containership
            mechanism, an architect can build any type of partitioning they want.
            Here we discuss an important aspect of styles, the top-level partitioning in an architecture
            Two types of top-level architecture partitioning: layered and modular

                Dan : see "8-3 layered vs modular architecture partitioning"

            One type of architecture familiar to many is the layered monolith. The other is an architecture style
            popularized by Simon Brown called a modular monolith, a single deployment unit associated with a
            database and partitioned around domains rather than technical capabilities.

                Dan: see "8-4 technical vs domain.png"

            The other architectural variation in Figure 8-4 represents domain partitioning,
            inspired by the Eric Evan book Domain-Driven Design, which is a modeling techni‐
            que for decomposing complex software systems. In DDD, the architect identifies
            domains or workflows independent and decoupled from each other. The microservi‐
            ces architecture style (discussed in Chapter 17) is based on this philosophy.

            Architects using technical partitioning organize the components of the system by
            technical capabilities: presentation, business rules, persistence, and so on. Thus, one
            of the organizing principles of this architecture is separation of technical concerns.
            This in turn creates useful levels of decoupling: if the service layer is only connected
            to the persistence layer below and business rules layer above, then changes in persis‐
            tence will only potentially affect those layers. This style of partitioning provides a
            decoupling technique, reducing rippling side effects on dependent components.

            Domain partitioning
                Domain-partitioned architectures separate top-level components by workflows
                and/or domains.
                Advantages
                    • Modeled more closely toward how the business functions rather than an implementation detail
                    • Easier to utilize the Inverse Conway Maneuver to build cross-functional teams around domains
                    • Aligns more closely to the modular monolith and microservices architecture styles
                    • Message flow matches the problem domain
                    • Easy to migrate data and components to distributed architecture
                Disadvantage
                    • Customization code appears in multiple places

            Technical partitioning
                Technically partitioned architectures separate top-level components based on techni‐
                cal capabilities rather than discrete workflows. This may manifest as layers inspired
                by Model-View-Controller separation or some other ad hoc technical partitioning.

                Advantages
                    • Clearly separates customization code.
                    • Aligns more closely to the layered architecture pattern.
                Disadvantages
                    • Higher degree of global coupling. Changes to either the Common or Local compo‐
                    nent will likely affect all the other components.
                    • Developers may have to duplicate domain concepts in both common and local layers.
                    • Typically higher coupling at the data level. In a system like this, the application
                    and data architects would likely collaborate to create a single database, including
                    customization and domains. That in turn creates difficulties in untangling the
                    data relationships if the architects later want to migrate this architecture to a dis‐
                    tributed system.

    Developer Role
        Developers typically take components, jointly designed with the architect role, and
        further subdivide them into classes, functions, or subcomponents. In general, class
        and function design is the shared responsibility of architects, tech leads, and develop‐
        ers, with the lion’s share going to developer roles.

!!!!!Component Identification Flow
        Component identification works best as an iterative process, producing candidates
        and refinements through feedback, illustrated in

            Dan : "8-8 component identification process"

        Identifying Initial Components
            Before any code exists for a software project, the architect must somehow determine
            what top-level components to begin with, based on what type of top-level partition‐
            ing they choose (domain or technical..see above).

        Assign Requirements to Components
            Once an architect has identified initial components, the next step aligns requirements
            (or user stories) to those components to see how well they fit. This may entail creat‐
            ing new components, consolidating existing ones, or breaking components apart
            because they have too much responsibility

        Analyze Roles and Responsibilities
            When assigning stories to components, the architect also looks at the roles and
            responsibilities elucidated during the requirements to make sure that the granularity
            matches. Thinking about both the roles and behaviors the application must support
            allows the architect to align the component and domain granularity. One of the great‐
            est challenges for architects entails discovering the correct granularity for compo‐
            nents, which encourages the iterative approach described here.

        Analyze Architecture Characteristics
            When assigning requirements to components, the architect should also look at the
            architecture characteristics discovered earlier in order to think about how they might
            impact component division and granularity. For example, while two parts of a system
            might deal with user input, the part that deals with hundreds of concurrent users will
            need different architecture characteristics than another part that needs to support
            only a few. Thus, while a purely functional view of component design might yield a
            single component to handle user interaction, analyzing the architecture characteris‐
            tics will lead to a subdivision

        Restructure Components
            Feedback is critical in software design. Thus, architects must continually iterate on
            their component design with developers. Designing software provides all kinds of
            unexpected difficulties—no one can anticipate all the unknown issues that usually
            occur during software projects. Thus, an iterative approach to component design is
            key. First, it’s virtually impossible to account for all the different discoveries and edge
            cases that will arise that encourage redesign. Secondly, as the architecture and devel‐
            opers delve more deeply into building the application, they gain a more nuanced
            understanding of where behavior and roles should lie

    Discovering Components
        Architects, often in collaboration with other roles such as developers, business ana‐
        lysts, and subject matter experts, create an initial component design based on general
        knowledge of the system and how they choose to decompose it, based on technical or
        domain partitioning. The team goal is an initial design that partitions the problem
        space into coarse chunks that take into account differing architecture characteristics.

        Actor/Actions approach
            The actor/actions approach is a popular way that architects use to map requirements
            to components. In this approach, originally defined by the Rational Unified Process,
            architects identify actors who perform activities with the application and the actions
            those actors may perform. It provides a technique for discovering the typical users of
            the system and what kinds of things they might do with the system.

        Event storming
            Event storming as a component discovery technique comes from domain-driven
            design (DDD) and shares popularity with microservices, also heavily influenced by
            DDD. In event storming, the architect assumes the project will use messages and/or
            events to communicate between the various components. To that end, the team tries
            to determine which events occur in the system based on requirements and identified
            roles, and build components around those event and message handlers. This works
            well in distributed architectures like microservices that use events and messages,
            because it helps architects define the messages used in the eventual system.

        Workfow approach
            An alternative to event storming offers a more generic approach for architects not
            using DDD or messaging. The workflow approach models the components around
            workflows, much like event storming, but without the explicit constraints of building
            a message-based system. A workflow approach identifies the key roles, determines
            the kinds of workflows these roles engage in, and builds components around the
            identified activities.

!!!!!!!
    Architecture Quantum Redux: Choosing Between Monolithic Versus Distributed Architectures
        the architecture quantum defines the scope of architecture
        characteristics. That in turn leads an architect toward an important decision as they
        finish their initial component design: should the architecture be monolithic or distributed?

        A monolithic architecture typically features a single deployable unit, including all
        functionality of the system that runs in the process, typically connected to a single
        database. Types of monolithic architectures include the layered and modular monolith

        A distributed architecture is the opposite—the
        application consists of multiple services running in their own ecosystem, communicating
        via networking protocols. Distributed architectures may feature finer-grained
        deployment models, where each service may have its own release cadence and engineering
        practices, based on the development team and their priorities.

!!!!    Each architecture style offers a variety of trade-offs, covered in Part II. However, the
        fundamental decision rests on how many quanta the architecture discovers during
        the design process. If the system can manage with a single quantum (in other words,
        one set of architecture characteristics), then a monolith architecture offers many
        advantages. On the other hand, differing architecture characteristics for components,
        requires a distributed architecture to accommodate differing architecture characteristics.

!!!!!   The ability to determine a fundamental design characteristic of architecture (monolith
        versus distributed) early in the design process highlights one of the advantages of
        using the architecture quantum as a way of analyzing architecture characteristics scope and coupling

========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
PART II Architecture Styles

    The difference between an architecture style and an architecture pattern can be confusing.
!!  We define an architecture style as the overarching structure of how the user
    interface and backend source code are organized (such as within layers of a monolithic
    deployment or separately deployed services) and how that source code interacts
    with a datastore.
!!  Architecture patterns, on the other hand, are lower-level design
    structures that help form specific solutions within an architecture style (such as how
    to achieve high scalability or high performance within a set of operations or between sets of services).

!!  Architects must understand the various styles and the trade-offs encapsulated within each to make effective
    decisions; each architecture style embodies a well-known set of trade-offs that help an
    architect make the right choice for a particular business problem.

========================================================================================================================
Chapter 9. Foundations

    Architecture styles, sometimes called architecture patterns, describe a named rela‐
    tionship of components covering a variety of architecture characteristics. An archi‐
    tecture style name, similar to design patterns, creates a single name that acts as
    shorthand between experienced architects. For example, when an architect talks
    about a layered monolith, their target in the conversation understands aspects of
    structure, which kinds of architecture characteristics work well (and which ones can
    cause problems), typical deployment models, data strategies, and a host of other
    information. Thus, architects should be familiar with the basic names of fundamental
    generic architecture styles.

    Fundamental Patterns
        Several fundamental patterns appear again and again throughout the history of soft‐
        ware architecture because they provide a useful perspective on organizing code,
        deployments, or other aspects of architecture.

        Big Ball of Mud
            Architects refer to the absence of any discernible architecture structure as a Big Ball of
            Mud, named after the eponymous anti-pattern defined in a paper released in 1997 by
            Brian Foote and Joseph Yoder:
                A Big Ball of Mud is a haphazardly structured, sprawling, sloppy, duct-tape-and-balingwire, spaghetti-code
                jungle. These systems show unmistakable signs of unregulated
                growth, and repeated, expedient repair. Information is shared promiscuously among
                distant elements of the system, often to the point where nearly all the important information
                becomes global or duplicated.
                The overall structure of the system may never have been well defined.
                If it was, it may have eroded beyond recognition.

            In general, architects want to avoid this type of architecture at all costs. The lack of
            structure makes change increasingly difficult. This type of architecture also suffers
            from problems in deployment, testability, scalability, and performance.

                Dan: see "9-1 big ball of mud"

        Unitary Architecture
            Few unitary architectures exist outside embedded systems and other highly con‐
            strained environments. Generally, software systems tend to grow in functionality over
            time, requiring separation of concerns to maintain operational architecture charac‐
            teristics, such as performance and scale.

        Client/Server
            Over time, various forces required partitioning away from a single system; how to do
            that forms the basis for many of these styles. Many architecture styles deal with how
            to efficiently separate parts of the system.
!!!!        A fundamental style in architecture separates technical functionality between frontend
            and backend, called a two-tier, or client/server, architecture. Many different flavors
            of this architecture exist, depending on the era and computing capabilities.

            Desktop + database server
                An early personal computer architecture encouraged developers to write rich desktop
                applications in user interfaces like Windows, separating the data into a separate data‐
                base server. This architecture coincided with the appearance of standalone database
                servers that could connect via standard network protocols. It allowed presentation
                logic to reside on the desktop, while the more computationally intense action (both in
                volume and complexity) occurred on more robust database servers.

            Browser + web server
                Once modern web development arrived, the common split became web browser connected
                 to web server (which in turn was connected to a database server). The separation
                of responsibilities was similar to the desktop variant but with even thinner
                clients as browsers, allowing a wider distribution both inside and outside firewalls.
                Even though the database is separate from the web server, architects often still consider
                this a two-tier architecture because the web and database servers run on one
                class of machine within the operations center and the user interface runs on the user’s
                browser.

            Three-tier
                An architecture that became quite popular during the late 1990s was a three-tier
                architecture, which provided even more layers of separation. As tools like application
                servers became popular in Java and .NET, companies started building even more lay‐
                ers in their topology: a database tier using an industrial-strength database server, an
                application tier managed by an application server, frontend coded in generated
                HTML, and increasingly, JavaScript, as its capabilities expanded.

    Monolithic Versus Distributed Architectures
!!!     Architecture styles can be classified into two main types: monolithic (single deployment
        unit of all code) and distributed (multiple deployment units connected through
        remote access protocols)

        In this book we will describe in detail the following architecture styles:

!!!!!   Monolithic
            • Layered architecture (Chapter 10)
            • Pipeline architecture (Chapter 11)
            • Microkernel architecture (Chapter 12)

!!!!!   Distributed
            • Service-based architecture (Chapter 13)
            • Event-driven architecture (Chapter 14)
            • Space-based architecture (Chapter 15)
            • Service-oriented architecture (Chapter 16)
            • Microservices architecture (Chapter 17)

        Distributed architecture styles, while being much more powerful in terms of performance, scalability, and
        availability than monolithic architecture styles, have significant
        trade-offs for this power.
        A fallacy is something that is believed or assumed to be true but is not. All eight of the fallacies of
        distributed computing apply to distributed architectures today. The following sections describe each fallacy.

!!!         Fallacy #1: The Network Is Reliable
                Developers and architects alike assume that the network is reliable, but it is not.
                While networks have become more reliable over time, the fact of the matter is that
                networks still remain generally unreliable. This is significant for all distributed archi‐
                tectures because all distributed architecture styles rely on the network for communi‐
                cation to and from services, as well as between services.
                This is why things like timeouts and circuit breakers exist between services. The more a system relies on
                the network (such as microservices architecture), the potentially less reliable it becomes.

!!!         Fallacy #2: Latency Is Zero
                As Figure 9-3 shows, when a local call is made to another component via a method or
                function call, that time (t_local) is measured in nanoseconds or microseconds.
                However, when that same call is made through a remote access protocol (such as
                REST, messaging, or RPC), the time measured to access that service (t_remote) is
                measured in milliseconds. Therefore, t_remote will always be greater that t_local.
                Latency in any distributed architecture is not zero, yet most architects ignore this fal‐
                lacy, insisting that they have fast networks. Ask yourself this question: do you know
                what the average round-trip latency is for a RESTful call in your production environ‐
                ment? Is it 60 milliseconds? Is it 500 milliseconds?

                When using any distributed architecture, architects must know this latency average. It
                is the only way of determining whether a distributed architecture is feasible, particularly
                when considering microservices (see Chapter 17) due to the fine-grained nature
!!!             of the services and the amount of communication between those services. Assuming
                an average of 100 milliseconds of latency per request, chaining together 10 service
                calls to perform a particular business function adds 1,000 milliseconds to the request!

!!!         Fallacy #3: Bandwidth Is Infinite
                Bandwidth is usually not a concern in monolithic architectures, because once processing
                goes into a monolith, little or no bandwidth is required to process that business
                request. However, as shown in Figure 9-4, once systems are broken apart into
                smaller deployment units (services) in a distributed architecture such as microservices
                , communication to and between these services significantly utilizes bandwidth,
                causing networks to slow down, thus impacting latency (fallacy #2) and reliability
                (fallacy #1).
                To illustrate the importance of this fallacy, consider the two services shown in
                Figure 9-4. Let’s say the lefthand service manages the wish list items for the website,
                and the righthand service manages the customer profile. Whenever a request for a
                wish list comes into the lefthand service, it must make an interservice call to the
                righthand customer profile service to get the customer name because that data is
                needed in the response contract for the wish list, but the wish list service on the left‐
                hand side doesn’t have the name. The customer profile service returns 45 attributes
                totaling 500 kb to the wish list service, which only needs the name (200 bytes). This is
                a form of coupling referred to as stamp coupling. This may not sound significant, but
                requests for the wish list items happen about 2,000 times a second. This means that
                this interservice call from the wish list service to the customer profile service happens
                2,000 times a second. At 500 kb for each request, the amount of bandwidth used for
                that one interservice call (out of hundreds being made that second) is 1 Gb!
                Stamp coupling in distributed architectures consumes significant amounts of band‐
                width. If the customer profile service were to only pass back the data needed by the
                wish list service (in this case 200 bytes), the total bandwidth used to transmit the data
                is only 400 kb
                Stamp coupling can be resolved in the following ways:
                    • Create private RESTful API endpoints
                    • Use field selectors in the contract
                    • Use GraphQL to decouple contracts
                    • Use value-driven contracts with consumer-driven contracts (CDCs)
                    • Use internal messaging endpoints
                Regardless of the technique used, ensuring that the minimal amount of data is passed
                between services or systems in a distributed architecture is the best way to address
                this fallacy.

!!!         Fallacy #4: The Network Is Secure
                Most architects and developers get so comfortable using virtual private networks
                (VPNs), trusted networks, and firewalls that they tend to forget about this fallacy of
                distributed computing: the network is not secure. Security becomes much more challenging
                in a distributed architecture. As shown in Figure 9-5, each and every end‐
                point to each distributed deployment unit must be secured so that unknown or bad
                requests do not make it to that service. The surface area for threats and attacks
                increases by magnitudes when moving from a monolithic to a distributed architecture.
                Having to secure every endpoint, even when doing interservice communication,
                is another reason performance tends to be slower in synchronous, highly-distributed
                architectures such as microservices or service-based architecture

!!!         Fallacy #5: The Topology Never Changes
                Suppose an architect comes into work on a Monday morning, and everyone is run‐
                ning around like crazy because services keep timing out in production. The architect
                works with the teams, frantically trying to figure out why this is happening. No new
                services were deployed over the weekend. What could it be? After several hours the
                architect discovers that a minor network upgrade happened at 2 a.m. that morning.
                This supposedly “minor” network upgrade invalidated all of the latency assumptions,
                triggering timeouts and circuit breakers.

!!!         Fallacy #6: There Is Only One Administrator
                Architects all the time fall into this fallacy, assuming they only need to collaborate
                and communicate with one administrator. As shown in Figure 9-7, there are dozens
                of network administrators in a typical large company

!!!         Fallacy #7: Transport Cost Is Zero
                Transport cost here does not refer to latency, but rather to actual cost in
                terms of money associated with making a “simple RESTful call.” Architects assume
                (incorrectly) that the necessary infrastructure is in place and sufficient for making a
                simple RESTful call or breaking apart a monolithic application. It is usually not. Distributed
                architectures cost significantly more than monolithic architectures, primarily
                due to increased needs for additional hardware, servers, gateways, firewalls, new
                subnets, proxies, and so on.

!!!         Fallacy #8: The Network Is Homogeneous
                Most architects and developers assume a network is homogeneous—made up by only
                one network hardware vendor. Nothing could be farther from the truth. Most compa‐
                nies have multiple network hardware vendors in their infrastructure, if not more.
                So what? The significance of this fallacy is that not all of those heterogeneous hard‐
                ware vendors play together well. Most of it works, but does Juniper hardware
                seamlessly integrate with Cisco hardware? Networking standards have evolved over
                the years, making this less of an issue, but the fact remains that not all situations,
                load, and circumstances have been fully tested, and as such, network packets occasionally get lost.

            Other Distributed Considerations
                In addition to the eight fallacies of distributed computing previously described, there
                are other issues and challenges facing distributed architecture that aren’t present in
                monolithic architectures.

!!!             Distributed logging
                    Performing root-cause analysis to determine why a particular order was dropped is
                    very difficult and time-consuming in a distributed architecture due to the distribu‐
                    tion of application and system logs. In a monolithic application there is typically only
                    one log, making it easier to trace a request and determine the issue. However, dis‐
                    tributed architectures contain dozens to hundreds of different logs, all located in a
                    different place and all with a different format, making it difficult to track down a
                    problem.
                    Logging consolidation tools such as Splunk help to consolidate information from var‐
                    ious sources and systems together into one consolidated log and console, but these
                    tools only scratch the surface of the complexities involved with distributed logging.

!!!             Distributed transactions
                    Architects and developers take transactions for granted in a monolithic architecture
                    world because they are so straightforward and easy to manage. Standard commits and
                    rollbacks executed from persistence frameworks leverage ACID (atomicity, consis‐
                    tency, isolation, durability) transactions to guarantee that the data is updated in a cor‐
                    rect way to ensure high data consistency and integrity. Such is not the case with
                    distributed architectures.
                    Distributed architectures rely on what is called eventual consistency to ensure the data
                    processed by separate deployment units is at some unspecified point in time all
                    synchronized into a consistent state. This is one of the trade-offs of distributed
                    architecture: high scalability, performance, and availability at the sacrifice of data
                    consistency and data integrity

                    Transactional sagas are one way to manage distributed transactions. Sagas utilize
                    either event sourcing for compensation or finite state machines to manage the state of
                    transaction. In addition to sagas, BASE transactions are used. BASE stands for (B)asic
                    availability, (S)oft state, and (E)ventual consistency. BASE transactions are not a piece
                    of software, but rather a technique. So state in BASE refers to the transit of data
                    from a source to a target, as well as the inconsistency between data sources. Based on
                    the basic availability of the systems or services involved, the systems will eventually
                    become consistent through the use of architecture patterns and messaging.

                        Dan: very nice article about transactional sagas here : https://microservices.io/patterns/data/saga.html

========================================================================================================================
Chapter 10. Layered Architecture Style

    The layered architecture, also known as the n-tiered architecture style, is one of the
    most common architecture styles. This style of architecture is the de facto standard
    for most applications, primarily because of its simplicity, familiarity, and low cost. It is
    also a very natural way to develop applications due to Conway’s law, which states that
    organizations that design systems are constrained to produce designs which are
    copies of the communication structures of these organizations. In most organizations
    there are user interface (UI) developers, backend developers, rules developers, and
    database experts (DBAs). These organizational layers fit nicely into the tiers of a tra‐
    ditional layered architecture, making it a natural choice for many business applications

    Topology
        Components within the layered architecture style are organized into logical horizon‐
        tal layers, with each layer performing a specific role within the application (such as
        presentation logic or business logic). Although there are no specific restrictions in
        terms of the number and types of layers that must exist, most layered architectures
        consist of four standard layers: presentation, business, persistence, and database

        Dan: check "10-1 layered architecture"

        Each layer in the architecture forms an abstraction around the work that
        needs to be done to satisfy a particular business request. For example, the presenta‐
        tion layer doesn’t need to know or worry about how to get customer data; it only
        needs to display that information on a screen in a particular format. Similarly, the
        business layer doesn’t need to be concerned about how to format customer data for
        display on a screen or even where the customer data is coming from; it only needs to
        get the data from the persistence layer, perform business logic against the data (such
        as calculating values or aggregating data), and pass that information up to the presentation layer

        This separation of concerns concept within the layered architecture style makes it easy
        to build effective roles and responsibility models within the architecture

        The layered architecture is a technically partitioned architecture (as opposed to a
        domain-partitioned architecture). Groups of components, rather than being grouped
        by domain (such as customer), are grouped by their technical role in the architecture
        (such as presentation or business). As a result, any particular business domain is
        spread throughout all of the layers of the architecture. For example, the domain of
        “customer” is contained in the presentation layer, business layer, rules layer, services
        layer, and database layer, making it difficult to apply changes to that domain. As a
        result, a domain-driven design approach does not work as well with the layered
        architecture style.

    Layers of Isolation
        Each layer in the layered architecture style can be either closed or open. A closed layer
        means that as a request moves top-down from layer to layer, the request cannot skip
        any layers, but rather must go through the layer immediately below it to get to the
        next layer (see Figure 10-3). For example, in a closed-layered architecture, a request
        originating from the presentation layer must first go through the business layer and
        then to the persistence layer before finally making it to the database layer.

        The layers of isolation concept means that changes made in one layer of the architec‐
        ture generally don’t impact or affect components in other layers, providing the con‐
        tracts between those layers remain unchanged. Each layer is independent of the other
        layers, thereby having little or no knowledge of the inner workings of other layers in
        the architecture. However, to support layers of isolation, layers involved with the
        major flow of the request necessarily have to be closed. If the presentation layer can
        directly access the persistence layer, then changes made to the persistence layer would
        impact both the business layer and the presentation layer, producing a very tightly
        coupled application with layer interdependencies between components. This type of
        architecture then becomes very brittle, as well as difficult and expensive to change.

        The layers of isolation concept also allows any layer in the architecture to be replaced
        without impacting any other layer. For example, you can leverage the layers of isolation
        concept within the layered architecture style to replace your older JavaServer Faces (JSF) presentation
        layer with React.js without impacting any other layer in the application.

    Adding Layers
        While closed layers facilitate layers of isolation and therefore help isolate change
        within the architecture, there are times when it makes sense for certain layers to be
        open.
        For example, suppose there are shared objects within the business layer that
        contain common functionality for business components (such as date and string utility
        classes, auditing classes, logging classes, and so on). Suppose there is an architec‐
        ture decision stating that the presentation layer is restricted from using these shared
        business objects

        One way to architecturally mandate this restriction is to add to the architecture a new
        services layer containing all of the shared business objects. Adding this new layer now
        architecturally restricts the presentation layer from accessing the shared business
        objects because the business layer is closed (see Figure 10-5). However, the new serv‐
        ices layer must be marked as open; otherwise the business layer would be forced to go
        through the services layer to access the persistence layer

            Dan: see "10-5 adding a new layer"

    Other Considerations
        The layered architecture makes for a good starting point for most applications when
        it is not known yet exactly which architecture style will ultimately be used. This is a
        common practice for many microservices efforts when architects are still determin‐
        ing whether microservices is the right architecture choice, but development must
        begin. However, when using this technique, be sure to keep reuse at a minimum and
        keep object hierarchies (depth of inheritance tree) fairly shallow so as to maintain a
        good level of modularity. This will help facilitate the move to another architecture
        style later on.

        watch out for with the layered architecture is the architecture sinkhole
        anti-pattern. This anti-pattern occurs when requests move from layer to layer as sim‐
        ple pass-through processing with no business logic performed within each layer. For
        example, suppose the presentation layer responds to a simple request from the user to
        retrieve basic customer data (such as name and address). The presentation layer
        passes the request to the business layer, which does nothing but pass the request on to
        the rules layer, which in turn does nothing but pass the request on to the persistence
        layer, which then makes a simple SQL call to the database layer to retrieve the cus‐
        tomer data. The data is then passed all the way back up the stack with no additional
        processing or logic to aggregate, calculate, apply rules, or transform the data. This
        results in unnecessary object instantiation and processing, impacting both memory
        consumption and performance.
        Every layered architecture will have at least some scenarios that fall into the architec‐
        ture sinkhole anti-pattern. The key to determining whether the architecture sinkhole
        anti-pattern is at play is to analyze the percentage of requests that fall into this cate‐
        gory. The 80-20 rule is usually a good practice to follow. For example, it is acceptable
        if only 20 percent of the requests are sinkholes

    Why Use This Architecture Style
        The layered architecture style is a good choice for small, simple applications or web‐
        sites. It is also a good architecture choice, particularly as a starting point, for situa‐
        tions with very tight budget and time constraints. Because of the simplicity and
        familiarity among developers and architects, the layered architecture is perhaps one
        of the lowest-cost architecture styles, promoting ease of development for smaller
        applications. The layered architecture style is also a good choice when an architect is
        still analyzing business needs and requirements and is unsure which architecture
        style would be best.

!!!!!Layered architecture characteristics ratings
        Dan: check "10-6 layered architecture characteristics ratings"

        Elasticity and scalability rate very low (one star) for the layered architecture, primar‐
        ily due to monolithic deployments and the lack of architectural modularity. Although
        it is possible to make certain functions within a monolith scale more than others, this
        effort usually requires very complex design techniques such as multithreading, inter‐
        nal messaging, and other parallel processing practices, techniques this architecture
        isn’t well suited for. However, because the layered architecture is always a single sys‐
        tem quantum due to the monolithic user interface, backend processing, and mono‐
        lithic database, applications can only scale to a certain point based on the single
        quantum.

========================================================================================================================
Chapter 11. Pipeline Architecture Style

    One of the fundamental styles in software architecture that appears again and again is
    the pipeline architecture (also known as the pipes and lters architecture). As soon as
    developers and architects decided to split functionality into discrete parts, this pat‐
    tern followed. Most developers know this architecture as this underlying principle
    behind Unix terminal shell languages, such as Bash and Zsh.

    Topology
        The pipes and filters coordinate in a specific fashion, with pipes forming one-way
        communication between filters, usually in a point-to-point fashion

        Dan: see "11-1 pipeline architecture"

        Pipes
            Pipes in this architecture form the communication channel between filters. Each pipe
            is typically unidirectional and point-to-point (rather than broadcast) for performance
            reasons, accepting input from one source and always directing output to another. The
            payload carried on the pipes may be any data format, but architects favor smaller
            amounts of data to enable high performance.

        Filters
            Filters are self-contained, independent from other filters, and generally stateless. Fil‐
            ters should perform one task only. Composite tasks should be handled by a sequence
            of filters rather than a single one.
            Four types of filters exist within this architecture style:
                Producer
                    The starting point of a process, outbound only, sometimes called the source.
                Transformer
                    Accepts input, optionally performs a transformation on some or all of the data,
                    then forwards it to the outbound pipe. Functional advocates will recognize this
                    feature as map.
                Tester
                    Accepts input, tests one or more criteria, then optionally produces output, based
                    on the test. Functional programmers will recognize this as similar to reduce.
                Consumer
                    The termination point for the pipeline flow. Consumers sometimes persist the
                    final result of the pipeline process to a database, or they may display the final
                    results on a user interface screen.

    Example
        The pipeline architecture pattern appears in a variety of applications, especially tasks
        that facilitate simple, one-way processing. For example, many Electronic Data Inter‐
        change (EDI) tools use this pattern, building transformations from one document
        type to another using pipes and filters. ETL tools (extract, transform, and load) lever‐
        age the pipeline architecture as well for the flow and modification of data from one
        database or data source to another

    Architecture Characteristics Ratings
        The pipeline architecture style is a technically partitioned architecture due to the par‐
        titioning of application logic into filter types (producer, tester, transformer, and con‐
        sumer). Also, because the pipeline architecture is usually implemented as a
        monolithic deployment, the architectural quantum is always one.

         Dan: check "11-3 pipeline architecture characteristic ratings"

========================================================================================================================
Chapter 12. Microkernel Architecture Style

    The microkernel architecture style (also referred to as the plug-in architecture) was
    coined several decades ago and is still widely used today. This architecture style is a
    natural fit for product-based applications (packaged and made available for download
    and installation as a single, monolithic deployment, typically installed on the custom‐
    er’s site as a third-party product) but is widely used in many nonproduct custom
    business applications as well.

    Topology
        The microkernel architecture style is a relatively simple monolithic architecture con‐
        sisting of two architecture components: a core system and plug-in components.
        Application logic is divided between independent plug-in components and the basic
        core system, providing extensibility, adaptability, and isolation of application features
        and custom processing logic.

            Dan: see "12-1 components of microkernel architecture"

        Core System
            The core system is formally defined as the minimal functionality required to run the
            system. The Eclipse IDE is a good example of this. The core system of Eclipse is just a
            basic text editor: open a file, change some text, and save the file. It’s not until you add
            plug-ins that Eclipse starts becoming a usable product

            Depending on the size and complexity, the core system can be implemented as a lay‐
            ered architecture or a modular monolith

        Plug-In Components
            Plug-in components are standalone, independent components that contain specialized
            processing, additional features, and custom code meant to enhance or extend the core system.
            Ideally, plug-in components should be independent of each other and have no dependencies between them.

            The communication between the plug-in components and the core system is generally
            point-to-point, meaning the “pipe” that connects the plug-in to the core system is
            usually a method invocation or function call to the entry-point class of the plug-in
            component. In addition, the plug-in component can be either compile-based or
            runtime-based. Runtime plug-in components can be added or removed at runtime
            without having to redeploy the core system or other plug-ins, and they are usually
            managed through frameworks such as Open Service Gateway Initiative (OSGi) for
            Java, Penrose (Java), Jigsaw (Java)
            Compile-based plug-in components are much simpler to manage but require the entire monolithic
            application to be redeployed when modified, added, or removed

            Alternatively, an easier approach shown in Figure 12-5 is to implement each plug-in
            component as a separate namespace or package name.
            When creating the namespace, we recommend the following semantics:
            app.plug-in.<domain>.<context>. For example, consider the namespace
            app.plugin.assessment.iphone6s. The second node (plugin) makes it clear this
            component is a plug-in and therefore should strictly adhere to the basic rules
            regarding plug-in components

            Plug-in components do not always have to be point-to-point communication with the
            core system. Other alternatives exist, including using REST or messaging as a means
            to invoke plug-in functionality, with each plug-in being a standalone service (or
            maybe even a microservice implemented using a container).
            Although this may sound like a good way to increase overall scalability, note that this topology
            is still only a single architecture quantum due to the monolithic
            core system. Every request must first go through the core system to get to the plug-in service.

            It is not a common practice for plug-in components to connect directly to a centrally
            shared database. Rather, the core system takes on this responsibility, passing whatever
            data is needed into each plug-in. The primary reason for this practice is decoupling.
            Making a database change should only impact the core system, not the plug-in components.
            That said, plug-ins can have their own separate data stores only accessible to
            that plug-in. For example, each electronic device assessment plug-in in the electronic
            recycling system example can have its own simple database or rules engine containing
            all of the specific assessment rules for each product. The data store owned by the
            plug-in component can be external (as shown in Figure 12-7), or it could be embedded

    Registry
        The core system needs to know about which plug-in modules are available and how
        to get to them. One common way of implementing this is through a plug-in registry.
        This registry contains information about each plug-in module, including things like
        its name, data contract, and remote access protocol details (depending on how the
        plug-in is connected to the core system). For example, a plug-in for tax software that
        flags high-risk tax audit items might have a registry entry that contains the name of
        the service (AuditChecker), the data contract (input data and output data), and the
        contract format (XML).

        The registry can be as simple as an internal map structure owned by the core system
        containing a key and the plug-in component reference, or it can be as complex as a
        registry and discovery tool either embedded within the core system or deployed
        externally (such as Apache ZooKeeper or Consul)

    Contracts
        The contracts between the plug-in components and the core system are usually stan‐
        dard across a domain of plug-in components and include behavior, input data, and
        output data returned from the plug-in component. Custom contracts are typically
        found in situations where plug-in components are developed by a third party where
        you have no control over the contract used by the plug-in. In such cases, it is com‐
        mon to create an adapter between the plug-in contract and your standard contract so
        that the core system doesn’t need specialized code for each plug-in

        Plug-in contracts can be implemented in XML, JSON, or even objects passed back
        and forth between the plug-in and the core system

    Examples and Use Cases
        Most of the tools used for developing and releasing software are implemented using
        the microkernel architecture. Some examples include the Eclipse IDE, PMD, Jira, and
        Jenkins, to name a few). Internet web browsers such as Chrome and Firefox are
        another common product example using the microkernel architecture: viewers and
        other plug-ins add additional capabilities that are not otherwise found in the basic
        browser representing the core system

    Architecture Characteristics Ratings
        Dan: see "12-8 microkernel architecture characteristic ratings"

        The microkernel architecture style is unique in that it is the only architecture style
        that can be both domain partitioned and technically partitioned. While most micro‐
        kernel architectures are technically partitioned, the domain partitioning aspect comes
        about mostly through a strong domain-to-architecture isomorphism. For example,
        problems that require different configurations for each location or client match
        extremely well with this architecture style. Another example is a product or applica‐
        tion that places a strong emphasis on user customization and feature extensibility
        (such as Jira or an IDE like Eclipse).

        Finally, microkernel architectures can be streamlined
        by unplugging unneeded functionality, therefore making the application run
        faster. A good example of this is Wildfly (previously the JBoss Application Server). By
        unplugging unnecessary functionality like clustering, caching, and messaging, the
        application server performs much faster than with these features in place.

========================================================================================================================
Chapter 13. Service-Based Architecture Style

    Service-based architecture is a hybrid of the microservices architecture style and is
    considered one of the most pragmatic architecture styles, mostly due to its architec‐
    tural flexibility. Although service-based architecture is a distributed architecture, it
    doesn’t have the same level of complexity and cost as other distributed architectures,
    such as microservices or event-driven architecture, making it a very popular choice
    for many business-related applications.

    Topology
        The basic topology of service-based architecture follows a distributed macro layered
        structure consisting of a separately deployed user interface, separately deployed
        remote coarse-grained services, and a monolithic database

            Dan: see "13-1 service based architecture"

        Services within this architecture style are typically coarse-grained “portions of an
        application” (usually called domain services) that are independent and separately
        deployed. Services are typically deployed in the same manner as any monolithic
        application would be (such as an EAR file, WAR file, or assembly) and as such do not
        require containerization (although you could deploy a domain service in a container
        such as Docker). Because the services typically share a single monolithic database, the
        number of services within an application context generally range between 4 and 12
        services, with the average being about 7 services.

        In most cases there is only a single instance of each domain service within a service based architecture.
        However, based on scalability, fault tolerance, and throughput
        needs, multiple instances of a domain service can certainly exist. Multiple instances
        of a service usually require some sort of load-balancing capability between the user
        interface and the domain service so that the user interface can be directed to a healthy
        and available service instance.

        While REST is typically used to access services from the user interface, messaging,
        remote procedure call (RPC), or even SOAP could be used as well. While an API
        layer consisting of a proxy or gateway can be used to access services from the user
        interface (or other external requests), in most cases the user interface accesses the
        services directly using a service locator pattern embedded within the user interface,
        API gateway, or proxy

        One important aspect of service-based architecture is that it typically uses a centrally
        shared database. This allows services to leverage SQL queries and joins in the same
        way a traditional monolithic layered architecture would. Because of the small number
        of services (4 to 12), database connections are not usually an issue in service-based
        architecture.

    Service Design and Granularity
        Because domain services in a service-based architecture are generally coarse-grained,
        each domain service is typically designed using a layered architecture style consisting
        of an API facade layer, a business layer, and a persistence layer. Another popular
        design approach is to domain partition each domain service using sub-domains simi‐
        lar to the modular monolith architecture style.

!!!     For example, consider a business request from the user interface to place an order (also known as catalog checkout).
        This single request, received by the API access facade within the OrderService
        domain service, internally orchestrates the single business request: place the order,
        generate an order ID, apply the payment, and update the product inventory for each
        product ordered. In the microservices architecture style, this would likely involve the
        orchestration of many separately deployed remote single-purpose services to com‐
        plete the request. This difference between internal class-level orchestration and exter‐
        nal service orchestration points to one of the many significant differences between
        service-based architecture and microservices in terms of granularity.
        Because domain services are coarse-grained, regular ACID (atomicity, consistency,
        isolation, durability) database transactions involving database commits and rollbacks
        are used to ensure database integrity within a single domain service
        Highly distributed architectures like microservices, on the other hand, usually have fine-grained
        services and use a distributed transaction technique known as BASE transactions
        (basic availability, soft state, eventual consistency) that rely on eventual consistency
        and hence do not support the same level of database integrity as ACID transactions in
        a service-based architecture.

        To illustrate this point, consider the example of a catalog checkout process within a
        service-based architecture. Suppose the customer places an order and the credit card
        used for payment has expired. Since this is an atomic transaction within the same ser‐
        vice, everything added to the database can be removed using a rollback and a notice
        sent to the customer stating that the payment cannot be applied. Now consider this
        same process in a microservices architecture with smaller fine-grained services. First,
        the OrderPlacement service would accept the request, create the order, generate an
        order ID, and insert the order into the order tables. Once this is done, the order ser‐
        vice would then make a remote call to the PaymentService, which would try to apply
        the payment. If the payment cannot be applied due to an expired credit card, then the
        order cannot be placed and the data is in an inconsistent state (the order information
        has already been inserted but has not been approved). In this case, what about the
        inventory for that order? Should it be marked as ordered and decremented? What if
        the inventory is low and another customer wishes to purchase the item? Should that
        new customer be allowed to buy it, or should the reserved inventory be reserved for
        the customer trying to place the order with an expired credit card? These are just a
        few of the questions that would need to be addressed when orchestrating a business
        process with multiple finer-grained services.

    Architecture Characteristics Ratings

        Dan: see "13-9 service architecture characteristic ratings"

        Service-based architecture is a domain-partitioned architecture, meaning that the
        structure is driven by the domain rather than a technical consideration (such as pre‐
        sentation logic or persistence logic

        Being a distributed architecture, the number of quanta can be greater than or equal to
        one. Even though there may be anywhere from 4 to 12 separately deployed services, if
        those services all share the same database or user interface, that entire system would
        be only a single quantum

        Although service-based architecture doesn’t contain any five-star ratings, it neverthe‐
        less rates high (four stars) in many important and vital areas. Breaking apart an appli‐
        cation into separately deployed domain services using this architecture style allows
        for faster change (agility), better test coverage due to the limited scope of the domain
        (testability), and the ability for more frequent deployments carrying less risk than a
        large monolith (deployability). These three characteristics lead to better time-to market, allowing an
        organization to deliver new features and bug fixes at a relatively high rate.

    When to Use This Architecture Style
        The flexibility of this architecture style (see “Topology Variants” on page 165) com‐
        bined with the number of three-star and four-star architecture characteristics ratings
        make service-based architecture one of the most pragmatic architecture styles available

        Maintaining and coordinating database transactions is always an issue with distributed
        architectures in that they typically rely on eventual consistency rather than
        traditional ACID (atomicity, consistency, isolation, and durability) transactions.
        However, service-based architecture preserves ACID transactions better than any
        other distributed architecture due to the coarse-grained nature of the domain serv‐
        ices. There are cases where the user interface or API gateway might orchestrate two or
        more domain services, and in these cases the transaction would need to rely on sagas
        and BASE transactions. However, in most cases the transaction is scoped to a particu‐
        lar domain service, allowing for the traditional commit and rollback transaction
        functionality found in most monolithic applications.

        Lastly, service-based architecture is a good choice for achieving a good level of archi‐
        tectural modularity without having to get tangled up in the complexities and pitfalls
        of granularity. As services become more fine-grained, issues surrounding orchestra‐
        tion and choreography start to appear. Both orchestration and choreography are
        required when multiple services must be coordinated to complete a certain business
        transaction. Orchestration is the coordination of multiple services through the use of
        a separate mediator service that controls and manages the workflow of the transac‐
        tion (like a conductor in an orchestra). Choreography, on the other hand, is the coor‐
        dination of multiple services by which each service talks to one another without the
        use of a central mediator (like dancers in a dance). As services become more fine grained, both orchestration
        and choreography are necessary to tie the services
        together to complete the business transaction. However, because services within a
        service-based architecture tend to be more coarse-grained, they don’t require coordi‐
        nation nearly as much as other distributed architectures.

========================================================================================================================
Chapter 14. Event-Driven Architecture Style

!!!!
    The event-driven architecture style is a popular distributed asynchronous architecture
    style used to produce highly scalable and high-performance applications. It is also
    highly adaptable and can be used for small applications and as well as large, complex
    ones. Event-driven architecture is made up of decoupled event processing compo‐
    nents that asynchronously receive and process events. It can be used as a standalone
    architecture style or embedded within other architecture styles (such as an eventdriven microservices architecture).

    Most applications follow what is called a request-based model (illustrated in
    Figure 14-1). In this model, requests made to the system to perform some sort of
    action are send to a request orchestrator. The request orchestrator is typically a user
    interface, but it can also be implemented through an API layer or enterprise service
    bus. The role of the request orchestrator is to deterministically and synchronously
    direct the request to various request processors. The request processors handle the
    request, either retrieving or updating information in a database.

        Dan: see "14-1 event driven architecture - request based model"

    Topology
        There are two primary topologies within event-driven architecture: the mediator top‐
        ology and the broker topology. The mediator topology is commonly used when you
        require control over the workflow of an event process, whereas the broker topology is
        used when you require a high degree of responsiveness and dynamic control over the
        processing of an event. Because the architecture characteristics and implementation
        strategies differ between these two topologies, it is important to understand each one
        to know which is best suited for a particular situation.

    Broker Topology
        The broker topology differs from the mediator topology in that there is no central
        event mediator. Rather, the message flow is distributed across the event processor
        components in a chain-like broadcasting fashion through a lightweight message
        broker (such as RabbitMQ, ActiveMQ, HornetQ, and so on). This topology is useful
        when you have a relatively simple event processing flow and you do not need central
        event orchestration and coordination.

        There are four primary architecture components within the broker topology: an ini‐
        tiating event, the event broker, an event processor, and a processing event. The initiat‐
        ing event is the initial event that starts the entire event flow, whether it be a simple
        event like placing a bid in an online auction or more complex events in a health bene‐
        fits system like changing a job or getting married. The initiating event is sent to an
        event channel in the event broker for processing. Since there is no mediator compo‐
        nent in the broker topology managing and controlling the event, a single event pro‐
        cessor accepts the initiating event from the event broker and begins the processing of
        that event. The event processor that accepted the initiating event performs a specific
        task associated with the processing of that event, then asynchronously advertises what
        it did to the rest of the system by creating what is called a processing event. This pro‐
        cessing event is then asynchronously sent to the event broker for further processing,
        if needed. Other event processors listen to the processing event, react to that event by
        doing something, then advertise through a new processing event what they did. This
        process continues until no one is interested in what a final event processor did.

            Dan: see "14-2 event driven - broker topology"

        Because of the decoupled asynchronous fire-and-forget broadcasting nature of the broker topology, topics (or topic
        exchanges in the case of AMQP) are usually used in the broker topology using a
        publish-and-subscribe messaging model

        It is always a good practice within the broker topology for each event processor to
        advertise what it did to the rest of the system, regardless of whether or not any other
        event processor cares about what that action was. This practice provides architectural
        extensibility if additional functionality is required for the processing of that event.

        In analyzing the prior example, notice that all of the event processors are highly
        decoupled and independent of each other. The best way to understand the broker
        topology is to think about it as a relay race. In a relay race, runners hold a baton (a
        wooden stick) and run for a certain distance (say 1.5 kilometers), then hand off the
        baton to the next runner, and so on down the chain until the last runner crosses the
        finish line. In relay races, once a runner hands off the baton, that runner is done with
        the race and moves on to other things. This is also true with the broker topology.
        Once an event processor hands off the event, it is no longer involved with the pro‐
        cessing of that specific event and is available to react to other initiating or processing
        events. In addition, each event processor can scale independently from one other to
        handle varying load conditions or backups in the processing within that event

        While performance, responsiveness, and scalability are all great benefits of the broker
        topology, there are also some negatives about it. First of all, there is no control over
        the overall workflow associated with the initiating event (in this case, the PlaceOrder
        event). It is very dynamic based on various conditions, and no one in the system
        really knows when the business transaction of placing an order is actually complete.
        Error handling is also a big challenge with the broker topology. Because there is no
        mediator monitoring or controlling the business transaction, if a failure occurs (such
        as the Payment event processor crashing and not completing its assigned task), no one
        in the system is aware of that crash. The business process gets stuck and is unable to
        move without some sort of automated or manual intervention. Furthermore, all other
        processes are moving along without regard for the error. For example, the Inventory
        event processor still decrements the inventory, and all other event processors react as
        though everything is fine

        The ability to restart a business transaction (recoverability) is also something not
        supported with the broker topology. Because other actions have asynchronously been
        taken through the initial processing of the initiating event, it is not possible to resub‐
        mit the initiating event. No component in the broker topology is aware of the state or
        even owns the state of the original business request, and therefore no one is responsi‐
        ble in this topology for restarting the business transaction (the initiating event) and
        knowing where it left off

    Mediator Topology
        The mediator topology of event-driven architecture addresses some of the shortcom‐
        ings of the broker topology described in the previous section. Central to this topology
        is an event mediator, which manages and controls the workflow for initiating events
        that require the coordination of multiple event processors. The architecture compo‐
        nents that make up the mediator topology are an initiating event, an event queue, an
        event mediator, event channels, and event processors

        Dan: see "14-5 event driven - mediator topology"

        Like in the broker topology, the initiating event is the event that starts the whole
        eventing process. Unlike the broker topology, the initiating event is sent to an initiat‐
        ing event queue, which is accepted by the event mediator. The event mediator only
        knows the steps involved in processing the event and therefore generates correspond‐
        ing processing events that are sent to dedicated event channels (usually queues) in a
        point-to-point messaging fashion. Event processors then listen to dedicated event
        channels, process the event, and usually respond back to the mediator that they have
        completed their work. Unlike the broker topology, event processors within the medi‐
        ator topology do not advertise what they did to the rest of the system.

        In most implementations of the mediator topology, there are multiple mediators, usu‐
        ally associated with a particular domain or grouping of events. This reduces the single
        point of failure issue associated with this topology and also increases overall through‐
        put and performance. For example, there might be a customer mediator that handles
        all customer-related events (such as new customer registration and profile update),
        and another mediator that handles order-related activities (such as adding an item to
        a shopping cart and checking out).

        The event mediator can be implemented in a variety of ways, depending on the
        nature and complexity of the events it is processing. For example, for events requiring
        simple error handling and orchestration, a mediator such as Apache Camel, Mule
        ESB, or Spring Integration will usually suffice.

        Given that it’s rare to have all events of one class of complexity, we recommend classi‐
        fying events as simple, hard, or complex and having every event always go through a
        simple mediator (such as Apache Camel or Mule). The simple mediator can then
        interrogate the classification of the event, and based on that classification, handle the
        event itself or forward it to another, more complex, event mediator. In this manner,
        all types of events can be effectively processed by the type of mediator needed for that
        event.

        Now that step 1 is complete, the mediator now moves to step 2 (see Figure 14-9) and
        generates three messages at the same time: email-customer, apply-payment, and
        adjust-inventory. These processing events are all sent to their respective queues. All
        three event processors receive these messages, perform their respective tasks, and
        notify the mediator that the processing has been completed. Notice that the mediator
        must wait until it receives acknowledgement from all three parallel processes before
        moving on to step 3. At this point, if an error occurs in one of the parallel event pro‐
        cessors, the mediator can take corrective action to fix the problem

!!!     The mediator component has knowledge and control over the workflow, something
        the broker topology does not have. Because the mediator controls the workflow, it
        can maintain event state and manage error handling, recoverability, and restart capa‐
        bilities. For example, suppose in the prior example the payment was not applied due
        to the credit card being expired. In this case the mediator receives this error condi‐
        tion, and knowing the order cannot be fulfilled (step 3) until payment is applied,
        stops the workflow and records the state of the request in its own persistent datastore.
        Once payment is eventually applied, the workflow can be restarted from where it left
        off

        Another inherent difference between the broker and mediator topology is how the
        processing events differ in terms of their meaning and how they are used. In the
        broker topology example in the previous section, the processing events were pub‐
        lished as events that had occurred in the system (such as order-created, paymentapplied, and email-sent).
        The event processors took some action, and other event
        processors react to that action. However, in the mediator topology, processing occur‐
        rences such as place-order, send-email, and fulfill-order are commands (things
        that need to happen) as opposed to events (things that have already happened). Also,
        in the mediator topology, a command must be processed, whereas an event can be
        ignored in the broker topology.

        While the mediator topology addresses the issues associated with the broker topol‐
        ogy, there are some negatives associated with the mediator topology. First of all, it is
        very difficult to declaratively model the dynamic processing that occurs within a
        complex event flow. As a result, many workflows within the mediator only handle the
        general processing, and a hybrid model combining both the mediator and broker
        topologies is used to address the dynamic nature of complex event processing (such
        as out-of-stock conditions or other nontypical errors). Furthermore, although the
        event processors can easily scale in the same manner as the broker topology, the
        mediator must scale as well, something that occasionally produces a bottleneck in the
        overall event processing flow. Finally, event processors are not as highly decoupled in
        the mediator topology as with the broker topology, and performance is not as good
        due to the mediator controlling the processing of the event

!!      The choice between the broker and mediator topology essentially comes down to a
        trade-off between workflow control and error handling capability versus high perfor‐
        mance and scalability. Although performance and scalability are still good within the
        mediator topology, they are not as high as with the broker topology.

    Asynchronous Capabilities
        The event-driven architecture style offers a unique characteristic over other architec‐
        ture styles in that it relies solely on asynchronous communication for both fire-and forget processing
        (no response required) as well as request/reply processing
        (response required from the event consumer). Asynchronous communication can be
        a powerful technique for increasing the overall responsiveness of a system.

        When the user does not need any information back (other than an acknowledgement
        or a thank you message), why make the user wait? Responsiveness is all about notify‐
        ing the user that the action has been accepted and will be processed momentarily,
        whereas performance is about making the end-to-end process faster.

        The main issue with asynchronous communications is error handling. While respon‐
        siveness is significantly improved, it is difficult to address error conditions, adding to
        the complexity of the event-driven system. The next section addresses this issue with
        a pattern of reactive architecture called the workflow event pattern.

    Error Handling
        The workflow event pattern of reactive architecture is one way of addressing the
        issues associated with error handling in an asynchronous workflow. This pattern is a
        reactive architecture pattern that addresses both resiliency and responsiveness. In
        other words, the system can be resilient in terms of error handling without an impact
        to responsiveness.

        The workflow event pattern leverages delegation, containment, and repair through
        the use of a workflow delegate, as illustrated in Figure 14-14. The event producer
        asynchronously passes data through a message channel to the event consumer. If the
        event consumer experiences an error while processing the data, it immediately dele‐
        gates that error to the workflow processor and moves on to the next message in the
        event queue. In this way, overall responsiveness is not impacted because the next
        message is immediately processed. If the event consumer were to spend the time try‐
        ing to figure out the error, then it is not reading the next message in the queue, there‐
        fore impacting the responsiveness not only of the next message, but all other
        messages waiting in the queue to be processed

            Dan: see "14-14 workflow event pattern"

        Once the workflow processor receives an error, it tries to figure out what is wrong
        with the message. This could be a static, deterministic error, or it could leverage some
        machine learning algorithms to analyze the message to see some anomaly in the data.
        Either way, the workflow processor programmatically (without human intervention)
        makes changes to the original data to try and repair it, and then sends it back to the
        originating queue. The event consumer sees this message as a new one and tries to
        process it again, hopefully this time with some success. Of course, there are many
        times when the workflow processor cannot determine what is wrong with the mes‐
        sage. In these cases the workflow processor sends the message off to another queue,
        which is then received in what is usually called a “dashboard,” an application that
        looks similar to the Microsoft’s Outlook or Apple’s Mail. This dashboard usually
        resides on the desktop of a person of importance, who then looks at the message,
        applies manual fixes to it, and then resubmits it to the original queue

    Preventing Data Loss
        Data loss is always a primary concern when dealing with asynchronous communications.
        Unfortunately, there are many places for data loss to occur within an event driven architecture. By data
        loss we mean a message getting dropped or never making
        it to its final destination. Fortunately, there are basic out-of-the-box techniques that
        can be leveraged to prevent data loss when using asynchronous messaging

!!!     Each of these areas of data loss can be mitigated through basic messaging techniques.
        Issue 1 (the message never makes it to the queue) is easily solved by leveraging persis‐
        tent message queues, along with something called synchronous send. Persisted mes‐
        sage queues support what is known as guaranteed delivery. When the message broker
        receives the message, it not only stores it in memory for fast retrieval, but also persists
        the message in some sort of physical data store (such as a filesystem or database). If
        the message broker goes down, the message is physically stored on disk so that when
        the message broker comes back up, the message is available for processing.
        Synchronous send does a blocking wait in the message producer until the broker has
        acknowledged that the message has been persisted

!!!     Issue 2 (Event Processor B de-queues the next available message and crashes before
        it can process the event) can also be solved using a basic technique of messaging
        called client acknowledge mode. By default, when a message is de-queued, it is imme‐
        diately removed from the queue (something called auto acknowledge mode). Client
        acknowledge mode keeps the message in the queue and attaches the client ID to the
        message so that no other consumers can read the message. With this mode, if Event
        Processor B crashes, the message is still preserved in the queue, preventing message
        loss in this part of the message flow.

    Broadcast Capabilities
        One of the other unique characteristics of event-driven architecture is the capability
        to broadcast events without knowledge of who (if anyone) is receiving the message
        and what they do with it
        Broadcasting is perhaps the highest level of decoupling between event processors
        because the producer of the broadcast message usually does not know which event
        processors will be receiving the broadcast message and more importantly, what they
        will do with the message.

    Request-Reply
        So far in this chapter we’ve dealt with asynchronous requests that don’t need an
        immediate response from the event consumer. But what if an order ID is needed
        when ordering a book? What if a confirmation number is needed when booking a
        flight? These are examples of communication between services or event processors
        that require some sort of synchronous communication.
        In event-driven architecture, synchronous communication is accomplished through
        request-reply messaging

        Each event channel within request-reply messaging consists of two queues: a
        request queue and a reply queue. The initial request for information is asynchro‐
        nously sent to the request queue, and then control is returned to the message pro‐
        ducer. The message producer then does a blocking wait on the reply queue, waiting
        for the response. The message consumer receives and processes the message and then
        sends the response to the reply queue. The event producer then receives the message
        with the response data.

            Dan: "14-19 request reply message processing"

        There are two primary techniques for implementing request-reply messaging. The
        first (and most common) technique is to use a correlation ID contained in the mes‐
        sage header. A correlation ID is a field in the reply message that is usually set to the
        message ID of the original request message

        The other technique used to implement request-reply messaging is to use a temporary
        queue for the reply queue. A temporary queue is dedicated to the specific request, cre‐
        ated when the request is made and deleted when the request ends. This technique, as
        illustrated in Figure 14-21, does not require a correlation ID because the temporary
        queue is a dedicated queue only known to the event producer for the specific request.

        While the temporary queue technique is much simpler, the message broker must cre‐
        ate a temporary queue for each request made and then delete it immediately after‐
        ward. Large messaging volumes can significantly slow down the message broker and
        impact overall performance and responsiveness. For this reason we usually recom‐
        mend using the correlation ID technique.

!!! Choosing Between Request-Based and Event-Based
        The request-based model and event-based model are both viable approaches for
        designing software systems. However, choosing the right model is essential to the
        overall success of the system. We recommend choosing the request-based model for
        well-structured, data-driven requests (such as retrieving customer profile data) when
        certainty and control over the workflow is needed. We recommend choosing the
        event-based model for flexible, action-based events that require high levels of respon‐
        siveness and scale, with complex and dynamic user processing


    Hybrid Event-Driven Architectures
        Some common architecture styles that leverage event-driven architecture as part of
        another architecture style include microservices and space-based architecture. Other
        hybrids that are possible include an event-driven microkernel architecture and an
        event-driven pipeline architecture.

    Architecture Characteristics Ratings

        Dan: "14-22 event driven architecture characteristics ratings"

        Event-driven architecture is primarily a technically partitioned architecture in that
        any particular domain is spread across multiple event processors and tied together
        through mediators, queues, and topics. Changes to a particular domain usually
        impact many event processors, mediators, and other messaging artifacts, hence why
        event-driven architecture is not domain partitioned.

        The number of quanta within event-driven architecture can vary from one to many
        quanta, which is usually based on the database interactions within each event
        processor and request-reply processing. Even though all communication in an event driven architecture is
        asynchronous, if multiple event processors share a single data‐
        base instance, they would all be contained within the same architectural quantum.
        The same is true for request-reply processing: even though the communication is still
        asynchronous between the event processors, if a request is needed right away from
        the event consumer, it ties those event processors together synchronously; hence they
        belong to the same quantum.

        Event-driven architecture gains five stars for performance, scalability, and fault toler‐
        ance, the primary strengths of this architecture style. High performance is achieved
        through asynchronous communications combined with highly parallel processing.
        As the request load increases, additional
        event processors can be programmatically added to handle the additional requests.

        Overall simplicity and testability rate relatively low with event-driven architecture,
        mostly due to the nondeterministic and dynamic event flows typically found within
        this architecture style. While deterministic flows within the request-based model are
        relatively easy to test because the paths and outcomes are generally known, such is
        not the case with the event-driven model


========================================================================================================================
Chapter 15. Space-Based Architecture Style

    Most web-based business applications follow the same general request flow: a request
    from a browser hits the web server, then an application server, then finally the data‐
    base server. While this pattern works great for a small set of users, bottlenecks start
    appearing as the user load increases, first at the web-server layer, then at the
    application-server layer, and finally at the database-server layer. The usual response to
    bottlenecks based on an increase in user load is to scale out the web servers. This is
    relatively easy and inexpensive, and it sometimes works to address the bottleneck
    issues. However, in most cases of high user load, scaling out the web-server layer just
    moves the bottleneck down to the application server. Scaling application servers can
    be more complex and expensive than web servers and usually just moves the bottle‐
    neck down to the database server, which is even more difficult and expensive to scale.
    Even if you can scale the database, what you eventually end up with is a triangleshaped topology,
    with the widest part of the triangle being the web servers (easiest to
    scale) and the smallest part being the database (hardest to scale),

    In any high-volume application with a large concurrent user load, the database will
    usually be the final limiting factor in how many transactions you can process concur‐
    rently. While various caching technologies and database scaling products help to
    address these issues, the fact remains that scaling out a normal application for
    extreme loads is a very difficult proposition.

    The space-based architecture style is specifically designed to address problems involv‐
    ing high scalability, elasticity, and high concurrency issues. It is also a useful architec‐
    ture style for applications that have variable and unpredictable concurrent user
    volumes

    General Topology
        Space-based architecture gets its name from the concept of tuple space, the technique
        of using multiple parallel processors communicating through shared memory. High
        scalability, high elasticity, and high performance are achieved by removing the central
        database as a synchronous constraint in the system and instead leveraging replicated
        in-memory data grids. Application data is kept in-memory and replicated among all
        the active processing units. When a processing unit updates data, it asynchronously
        sends that data to the database, usually via messaging with persistent queues. Process‐
        ing units start up and shut down dynamically as user load increases and decreases,
        thereby addressing variable scalability. Because there is no central database involved
        in the standard transactional processing of the application, the database bottleneck is
        removed, thus providing near-infinite scalability within the application.

!!!     There are several architecture components that make up a space-based architecture: a
        processing unit containing the application code, virtualized middleware used to man‐
        age and coordinate the processing units, data pumps to asynchronously send updated
        data to the database, data writers that perform the updates from the data pumps, and
        data readers that read database data and deliver it to processing units upon startup.

        Dan: see "15-2 spaced based architecture"

        Processing Unit
            The processing unit (illustrated in Figure 15-3) contains the application logic (or portions
            of the application logic). This usually includes web-based components as well as
            backend business logic. The contents of the processing unit vary based on the type of
            application. Smaller web-based applications would likely be deployed into a single
            processing unit, whereas larger applications may split the application functionality
            into multiple processing units based on the functional areas of the application. The
            processing unit can also contain small, single-purpose services (as with microservices
            ). In addition to the application logic, the processing unit also contains an in memory data grid and
            replication engine usually implemented through such
            products as Hazelcast, Apache Ignite, and Oracle Coherence.

        Virtualized Middleware
            The virtualized middleware handles the infrastructure concerns within the architec‐
            ture that control various aspects of data synchronization and request handling. The
            components that make up the virtualized middleware include a messaging grid, data
            grid, processing grid, and deployment manager

            Messaging grid
                The messaging grid, shown in Figure 15-4, manages input request and session state.
                When a request comes into the virtualized middleware, the messaging grid compo‐
                nent determines which active processing components are available to receive the
                request and forwards the request to one of those processing units. The complexity of
                the messaging grid can range from a simple round-robin algorithm to a more com‐
                plex next-available algorithm that keeps track of which request is being processed by
                which processing unit. This component is usually implemented using a typical web
                server with load-balancing capabilities (such as HA Proxy and Nginx)

            Data grid
                The data grid component is perhaps the most important and crucial component in
                this architecture style. In most modern implementations the data grid is implemented
                solely within the processing units as a replicated cache. However, for those replicated
                caching implementations that require an external controller, or when using a dis‐
                tributed cache, this functionality would reside in both the processing units as well as
                in the data grid component within the virtualized middleware. Since the messaging
                grid can forward a request to any of the processing units available, it is essential that
                each processing unit contains exactly the same data in its in-memory data grid.

!!!!!           Data is synchronized between processing units that contain the same named data
                grid. To illustrate this point, consider the following code in Java using Hazelcast that
                creates an internal replicated data grid for processing units containing customer profile
                information:
                    HazelcastInstance hz = Hazelcast.newHazelcastInstance();
                    Map<String, CustomerProfile> profileCache = hz.getReplicatedMap("CustomerProfile");
                All processing units needing access to the customer profile information would con‐
                tain this code. Changes made to the CustomerProfile named cache from any of the
                processing units would have that change replicated to all other processing units con‐
                taining that same named cache. A processing unit can contain as many replicated
                caches as needed to complete its work

                Data replication within the processing units also allows service instances to come up
                and down without having to read data from the database, providing there is at least
                one instance containing the named replicated cache. When a processing unit instance
                comes up, it connects to the cache provider (such as Hazelcast) and makes a request
                to get the named cache. Once the connection is made to the other processing units,
                the cache will be loaded from one of the other instances.

                Each processing unit knows about all other processing unit instances through the use
                of a member list. The member list contains the IP address and ports of all other pro‐
                cessing units using that same named cache.

                Notice that all three instances know about each other (including themselves). Sup‐
                pose instance 1 receives a request to update the customer profile information. When
                instance 1 updates the cache with a cache.put() or similar cache update method, the
                data grid (such as Hazelcast) will asynchronously update the other replicated caches
                with the same update, ensuring all three customer profile caches always remain in
                sync with one another.

            Processing grid
                The processing grid, illustrated in Figure 15-6, is an optional component within the
                virtualized middleware that manages orchestrated request processing when there are
                multiple processing units involved in a single business request. If a request comes in
                that requires coordination between processing unit types (e.g., an order processing
                unit and a payment processing unit), it is the processing grid that mediates and
                orchestrates the request between those two processing units.

            Deployment manager
                The deployment manager component manages the dynamic startup and shutdown of
                processing unit instances based on load conditions. This component continually
                monitors response times and user loads, starts up new processing units when load
                increases, and shuts down processing units when the load decreases. It is a critical
                component to achieving variable scalability (elasticity) needs within an application.

        Data Pumps
            A data pump is a way of sending data to another processor which then updates data
            in a database. Data pumps are a necessary component within space-based architec‐
            ture, as processing units do not directly read from and write to a database. Data
            pumps within a space-based architecture are always asynchronous, providing even‐
            tual consistency with the in-memory cache and the database. When a processing unit
            instance receives a request and updates its cache, that processing unit becomes the
            owner of the update and is therefore responsible for sending that update through the
            data pump so that the database can be updated eventually.

            Messaging is a good choice for data pumps when using a space-based architecture. Not
            only does messaging support asynchronous communication, but it also supports
            guaranteed delivery and preserving message order through first-in, first-out (FIFO)
            queueing. Furthermore, messaging provides a decoupling between the processing
            unit and the data writer so that if the data writer is not available, uninterrupted pro‐
            cessing can still take place within the processing units

            In most cases there are multiple data pumps, each one usually dedicated to a particu‐
            lar domain or subdomain (such as customer or inventory). Data pumps can be dedi‐
            cated to each type of cache (such as CustomerProfile, CustomerWishlist, and so
            on), or they can be dedicated to a processing unit domain (such as Customer) con‐
            taining a much larger and general cache.

        Data Writers
            The data writer component accepts messages from a data pump and updates the data‐
            base with the information contained in the message of the data pump (see
            Figure 15-7). Data writers can be implemented as services, applications, or data hubs
            (such as Ab Initio). The granularity of the data writers can vary based on the scope of
            the data pumps and processing units.

        Data Readers
            Whereas data writers take on the responsibility for updating the database, data read‐
            ers take on the responsibility for reading data from the database and sending it to the
            processing units via a reverse data pump. In space-based architecture, data readers
            are only invoked under one of three situations: a crash of all processing unit instances
            of the same named cache, a redeployment of all processing units within the same
            named cache, or retrieving archive data not contained in the replicated cache

            When instances of a class of processing unit
            start coming up, each one tries to grab a lock on the cache. The first one to get the
            lock becomes the temporary cache owner; the others go into a wait state until the lock
            is released (this might vary based on the type of cache implementation being used,
            but regardless, there is one primary owner of the cache in this scenario). To load the
            cache, the instance that gained temporary cache owner status sends a message to a
            queue requesting data. The data reader component accepts the read request and then
            performs the necessary database query logic to retrieve the data needed by the pro‐
            cessing unit. As the data reader queries data from the database, it sends that data to a
            different queue (called a reverse data pump). The temporary cache owner processing
            unit receives the data from the reverse data pump and loads the cache. Once all the
            data is loaded, the temporary owner releases the lock on the cache, all other instances
            are then synchronized, and processing can begin

    Data Collisions
        When using replicated caching in an active/active state where updates can occur to
        any service instance containing the same named cache, there is the possibility of a
        data collision due to replication latency. A data collision occurs when data is updated
        in one cache instance (cache A), and during replication to another cache instance
        (cache B), the same data is updated by that cache (cache B). In this scenario, the local
        update to cache B will be overridden through replication by the old data from cache
        A, and through replication the same data in cache A will be overridden by the update
        from cache B.

        There are several factors that influence how many data collisions might occur: the
        number of processing unit instances containing the same cache, the update rate of the
        cache, the cache size, and finally the replication latency of the caching product.

        Dan: there is a formula in the book that can be used to calculate the collision rate

    Cloud Versus On-Premises Implementations
        Space-based architecture offers some unique options when it comes to the environ‐
        ments in which it is deployed. The entire topology, including the processing units,
        virtualized middleware, data pumps, data readers and writers, and the database, can
        be deployed within cloud-based environments on-premises (“on-prem”). However,
        this architecture style can also be deployed between these environments, offering a
        unique feature not found in other architecture styles.

        A powerful feature of this architecture style (as illustrated in Figure 15-11) is to
        deploy applications via processing units and virtualized middleware in managed
        cloud-based environments while keeping the physical databases and corresponding
        data on-prem.

    Replicated Versus Distributed Caching
        Space-based architecture relies on caching for the transactional processing of an
        application. Removing the need for direct reads and writes to a database is how
        space-based architecture is able to support high scalability, high elasticity, and high
        performance. Space-based architecture mostly relies on replicated caching, although
        distributed caching can be used as well.
        With replicated caching, as illustrated in Figure 15-12, each processing unit contains
        its own in-memory data grid that is synchronized between all processing units using
        that same named cache. When an update occurs to a cache within any of the process‐
        ing units, the other processing units are automatically updated with the new
        information.

        Replicated caching is not only extremely fast, but it also supports high levels of fault
        tolerance. Since there is no central server holding the cache, replicated caching does
        not have a single point of failure. There may be exceptions to this rule, however,
        based on the implementation of the caching product used.

        While replicated caching is the standard caching model for space-based architecture,
        there are some cases where it is not possible to use replicated caching. These situa‐
        tions include high data volumes (size of the cache) and high update rates to the cache
        data. Internal memory caches in excess of 100 MB might start to cause issues with
        regard to elasticity and high scalability due to the amount of memory used by each
        processing unit. Processing units are generally deployed within a virtual machine (or
        in some cases represent the virtual machine). Each virtual machine only has a certain
        amount of memory available for internal cache usage, limiting the number of pro‐
        cessing unit instances that can be started to process high-throughput situations

!!!     Distributed caching requires an external server or service
        dedicated to holding a centralized cache. In this model the processing units do
        not store data in internal memory, but rather use a proprietary protocol to access the
        data from the central cache server.Distributed caching supports high levels of data
        consistency because the data is all in one place and does not need to be replicated.
        However, this model has less performance than replicated caching because the cache
        data must be accessed remotely, adding to the overall latency of the system. Fault tol‐
        erance is also an issue with distributed caching. If the cache server containing the
        data goes down, no data can be accessed or updated from any of the processing units,
        rendering them nonoperational.

        When the size of the cache is relatively small (under 100 MB) and the update rate of
        the cache is low enough that the replication engine of the caching product can keep
        up with the cache updates, the decision between using a replicated cache and a dis‐
        tributed cache becomes one of data consistency versus performance and fault toler‐
        ance. A distributed cache will always offer better data consistency over a replicated
        cache because the cache of data is in a single place (as opposed to being spread across
        multiple processing units). However, performance and fault tolerance will always be
        better when using a replicated cache. Many times this decision comes down to the
        type of data being cached in the processing units. The need for highly consistent data
        (such as inventory counts of the available products) usually warrants a distributed
        cache, whereas data that does not change often (such as reference data like name/
        value pairs, product codes, and product descriptions) usually warrants a replicated
        cache for quick lookup.

        Dan: see "15-3 distributed caching"

!!!!!!
        Decision criteria                       Replicated cache                                    Distributed cache
        Optimization                            Performance                                         Consistency
        Cache size                              Small (<100 MB)                                     Large (>500 MB)
        Type of data                            Relatively static                                   Highly dynamic
        Update frequency                        Relatively low                                      High update rate
        Fault tolerance                         High                                                Low

    Near-Cache Considerations
        A near-cache is a type of caching hybrid model bridging in-memory data grids with a
        distributed cache. In this model (illustrated in Figure 15-14) the distributed cache is
        referred to as the full backing cache, and each in-memory data grid contained within
        each processing unit is referred to as the front cache. The front cache always contains
        a smaller subset of the full backing cache, and it leverages an eviction policy to remove
        older items so that newer ones can be added. The front cache can be what is known as
        a most recently used (MRU) cache containing the most recently used items or a most
        frequently used (MFU) cache containing the most frequently used items. Alterna‐
        tively, a random replacement eviction policy can be used in the front cache so that
        items are removed in a random manner when space is needed to add a new item.
        Random replacement (RR) is a good eviction policy when there is no clear analysis of
        the data with regard to keeping either the latest used versus the most frequently used.

!!!!!   While the front caches are always kept in sync with the full backing cache, the front
        caches contained within each processing unit are not synchronized between other
        processing units sharing the same data. This means that multiple processing units
        sharing the same data context (such as a customer profile) will likely all have different
        data in their front cache. This creates inconsistencies in performance and responsive‐
        ness between processing units because each processing unit contains different data in
        the front cache. For this reason we do not recommended using a near-cache model
        for space-based architecture.

    Implementation Examples
        Space-based architecture is well suited for applications that experience high spikes in
        user or request volume and applications that have throughput in excess of 10,000
        concurrent users. Examples of space-based architecture include applications like
        online concert ticketing systems and online auction systems. Both of these examples
        require high performance, high scalability, and high levels of elasticity

        First, there are only a certain number of tickets available, regardless of the seating preferences. Seating
        availability must continually be updated and made available as fast as possible given
        the high number of concurrent requests. Also, assuming assigned seats are an option,
        seating availability must also be updated as fast as possible. Continually accessing a
        central database synchronously for this sort of system would likely not work—it
        would be very difficult for a typical database to handle tens of thousands of concur‐
        rent requests through standard database transactions at this level of scale and update
        frequency.

        An instantaneous increase in the number of concurrent users wanting to purchase concert tickets
        would be immediately recognized by the deployment manager, which in turn would
        start up a large number of processing units to handle the large volume of requests.
        Optimally, the deployment manager would be configured to start up the necessary
        number of processing units shortly before the tickets went on sale, therefore having
        those instances on standby right before the significant increase in user load.

    Architecture Characteristics Ratings

        Dan: see "15-15 spaced based architecture characteristics ratings"

        Notice that space-based architecture maximizes elasticity, scalability, and perfor‐
        mance (all five-star ratings). These are the driving attributes and main advantages of
        this architecture style. High levels of all three of these architecture characteristics are
        achieved by leveraging in-memory data caching and removing the database as a con‐
        straint. As a result, processing millions of concurrent users is possible using this
        architecture style.
        there is a trade-off for this advantage, specifically with regard to
        overall simplicity and testability. Space-based architecture is a very complicated
        architecture style due to the use of caching and eventual consistency of the primary
        data store, which is the ultimate system of record. Care must be taken to ensure no
        data is lost in the event of a crash in any of the numerous moving parts of this archi‐
        tecture style

        Cost is another factor when choosing this architecture style. Space-based architecture
        is relatively expensive, mostly due to licensing fees for caching products and high
        resource utilization within cloud and on-prem systems due to high scalability and
        elasticity.

        The number of quanta within space-based architecture can vary based on how the
        user interface is designed and how communication happens between processing
        units. Because the processing units do not communicate synchronously with the
        database, the database itself is not part of the quantum equation. As a result, quanta
        within a space-based architecture are typically delineated through the association
        between the various user interfaces and the processing units. Processing units that
        synchronously communicate with each other (or synchronously through the process‐
        ing grid for orchestration) would all be part of the same architectural quantum.


========================================================================================================================
Chapter 16. Orchestration-Driven Service-Oriented Architecture

    Architecture styles, like art movements, must be understood in the context of the era
    in which they evolved, and this architecture exemplifies this rule more than any
    other. The combination of external forces that often influence architecture decisions,
    combined with a logical but ultimately disastrous organizational philosophy, doomed
    this architecture to irrelevance. However, it provides a great example of how a partic‐
    ular organizational idea can make logical sense yet hinder most important parts of
    the development process.

    History and Philosophy
        This style of service-oriented architecture appeared just as companies were becoming
        enterprises in the late 1990s: merging with smaller companies, growing at a breakneck pace, and requiring more
         sophisticated IT to accommodate this growth. How‐
        ever, computing resources were scarce, precious, and commercial. Distributed
        computing had just become possible and necessary, and many companies needed the
        variable scalability and other beneficial characteristics.

        This style of architecture also exemplifies how far architects can push the idea of
        technical partitioning, which had good motivations but bad consequences.

    Topology
        Not all examples of this style of architecture had the exact layers illustrated in
        Figure 16-1, but they all followed the same idea of establishing a taxonomy of services
        within the architecture, each layer with a specific responsibility.

        Dan: "16-1 orchestration-driven service-oriented architecture"

        Service-oriented architecture is a distributed architecture; the exact demarcation of
        boundaries isn’t shown in Figure 16-1 because it varied based on organization

    Taxonomy
        The architect’s driving philosophy in this architecture centered around enterpriselevel reuse. Many large
        companies were annoyed at how much they had to continue
        to rewrite software, and they struck on a strategy to gradually solve that problem.
        Each layer of the taxonomy supported this goal

        Business Services
            Business services sit at the top of this architecture and provide the entry point. For
            example, services like ExecuteTrade or PlaceOrder represent domain behavior. One
            litmus test common at the time—could an architect answer affirmatively to the ques‐
            tion “Are we in the business of…” for each of these services?
            These service definitions contained no code—just input, output, and sometimes
            schema information. They were usually defined by business users, hence the name
            business services.

        Enterprise Services
            The enterprise services contain fine-grained, shared implementations. Typically, a
            team of developers is tasked with building atomic behavior around particular busi‐
            ness domains: CreateCustomer, CalculateQuote, and so on. These services are the
            building blocks that make up the coarse-grained business services, tied together via
            the orchestration engine.
            This separation of responsibility flows from the reuse goal in this architecture. If
            developers can build fine-grained enterprise services at just the correct level of granu‐
            larity, the business won’t have to rewrite that part of the business workflow again.
            Gradually, the business will build up a collection of reusable assets in the form of
            reusable enterprise services.

        Application Services
            Not all services in the architecture require the same level of granularity or reuse as the
            enterprise services. Application services are one-off, single-implementation services.
            For example, perhaps one application needs geo-location, but the organization
            doesn’t want to take the time or effort to make that a reusable service. An application
            service, typically owned by a single application team, solves these problems.

        Infrastructure Services
            Infrastructure services supply the operational concerns, such as monitoring, logging,
            authentication, and authorization. These services tend to be concrete implementa‐
            tions, owned by a shared infrastructure team that works closely with operations.

        Orchestration Engine
            The orchestration engine forms the heart of this distributed architecture, stitching
            together the business service implementations using orchestration, including features
            like transactional coordination and message transformation. This architecture is typi‐
            cally tied to a single relational database, or a few, rather than a database per service as
            in microservices architectures. Thus, transactional behavior is handled declaratively
            in the orchestration engine rather than in the database

            The orchestration engine defines the relationship between the business and enterprise
            services, how they map together, and where transaction boundaries lie. It also acts as
            an integration hub, allowing architects to integrate custom code with package and
            legacy software systems.

    Reuse…and Coupling
        A major goal of this architecture is reuse at the service level—the ability to gradually
        build business behavior that can be incrementally reused over time. Architects in this
        architecture were instructed to find reuse opportunities as aggressively as possible.

        However, architects only slowly realized the negative trade-offs of this design. First,
        when a team builds a system primarily around reuse, they also incur a huge amount
        of coupling between components. For example, in Figure 16-4, a change to the
        Customer service ripples out to all the other services, making change risky. Thus, in
        service-oriented architecture, architects struggled with making incremental change—
        each change had a potential huge ripple effect. That in turn led to the need for coor‐
        dinated deployments, holistic testing, and other drags on engineering efficiency

    Architecture Characteristics Ratings
        Many of the modern criteria we use to evaluate architecture now were not priorities
        when this architecture was popular

        Dan: see "16-5 service oriented architecture characteristic ratings"

        It has a single quantum even though it is a distributed architecture for two reasons. First, it
        generally uses a single database or just a few databases, creating coupling points
        within the architecture across many different concerns. Second, and more impor‐
        tantly, the orchestration engine acts as a giant coupling point—no part of the archi‐
        tecture can have different architecture characteristics than the mediator that
        orchestrates all behavior. Thus, this architecture manages to find the disadvantages of
        both monolithic and distributed architectures

        Modern engineering goals such as deployability and testability score disastrously in
        this architecture, both because they were poorly supported and because those were
        not important (or even aspirational) goals during that era.


========================================================================================================================
Chapter 17. Microservices Architecture

    Microservices is an extremely popular architecture style that has gained significant
    momentum in recent years. In this chapter, we provide an overview of the important
    characteristics that set this architecture apart, both topologically and philosophically

    History
        it was named fairly early in its usage and popularized
        by a famous blog entry by Martin Fowler and James Lewis entitled “Microservices"
        published in March 2014. They recognized many common characteristics in
        this relatively new architectural style and delineated them. Their blog post helped
        define the architecture for curious architects and helped them understand the underlying
         philosophy.

!!!!!   Microservices is heavily inspired by the ideas in domain-driven design (DDD), a logical
        design process for software projects. One concept in particular from DDD, bounded
        context, decidedly inspired microservices. The concept of bounded context
        represents a decoupling style. When a developer defines a domain, that domain
        includes many entities and behaviors, identified in artifacts such as code and database
        schemas. For example, an application might have a domain called CatalogCheckout,
        which includes notions such as catalog items, customers, and payment. In a traditional
        monolithic architecture, developers would share many of these concepts
        building reusable classes and linked databases. Within a bounded context, the inter‐
        nal parts, such as code and data schemas, are coupled together to produce work; but
        they are never coupled to anything outside the bounded context, such as a database
        or class definition from another bounded context. This allows each context to define
        only what it needs rather than accommodating other constituents.

!!!!!   While reuse is beneficial, remember the First Law of Software Architecture regarding
        trade-offs. The negative trade-off of reuse is coupling. When an architect designs a
        system that favors reuse, they also favor coupling to achieve that reuse, either by
        inheritance or composition.

        However, if the architect’s goal requires high degrees of decoupling, then they favor
        duplication over reuse. The primary goal of microservices is high decoupling, physi‐
        cally modeling the logical notion of bounded context.

    Topology

        Dan: see "17-1 microservices architecture"

!!      due to its single-purpose nature, the service size in microservices is much smaller than other distributed architectures

!!!!    Architects expect each service to include all necessary parts to operate independently, including databases and other
        dependent components

    Distributed
        Microservices form a distributed architecture: each service runs in its own process,
        which originally implied a physical computer but quickly evolved to virtual machines
        and containers. Decoupling the services to this degree allows for a simple solution to
        a common problem in architectures that heavily feature multitenant infrastructure
        for hosting applications. For example, when using an application server to manage
        multiple running applications, it allows operational reuse of network bandwidth,
        memory, disk space, and a host of other benefits.
        However, if all the supported appli‐
        cations continue to grow, eventually some resource becomes constrained on the
        shared infrastructure. Another problem concerns improper isolation between shared
        applications.

!!!     Separating each service into its own process solves all the problems brought on by
        sharing. Before the evolutionary development of freely available open source operat‐
        ing systems, combined with automated machine provisioning, it was impractical for
        each domain to have its own infrastructure. Now, however, with cloud resources and
        container technology, teams can reap the benefits of extreme decoupling, both at the
        domain and operational level.
        Performance is often the negative side effect of the distributed nature of microservi‐
        ces. Network calls take much longer than method calls, and security verification at
        every endpoint adds additional processing time, requiring architects to think care‐
        fully about the implications of granularity when designing the system.

!!!!    Because microservices is a distributed architecture, experienced architects advise
        against the use of transactions across service boundaries, making determining the
        granularity of services the key to success in this architecture.

    Bounded Context
        The driving philosophy of microservices is the notion of bounded context: each ser‐
        vice models a domain or workflow. Thus, each service includes everything necessary
        to operate within the application, including classes, other subcomponents, and data‐
        base schemas. This philosophy drives many of the decisions architects make within
        this architecture

        Granularity
            Architects struggle to find the correct granularity for services in microservices, and
            often make the mistake of making their services too small, which requires them to
            build communication links back between the services to do useful work.
                The term “microservice” is a label, not a description.
                —Martin Fowler

!!!!!       In other words, the originators of the term needed to call this new style something,
            and they chose “microservices” to contrast it with the dominant architecture style at
            the time, service-oriented architecture, which could have been called “gigantic serv‐
            ices”. However, many developers take the term “microservices” as a commandment,
            not a description, and create services that are too fine-grained

!!!!        The purpose of service boundaries in microservices is to capture a domain or work‐
            flow. In some applications, those natural boundaries might be large for some parts of
            the system—some business processes are more coupled than others. Here are some
            guidelines architects can use to help find the appropriate boundaries:
                Purpose
                    The most obvious boundary relies on the inspiration for the architecture style, a
                    domain. Ideally, each microservice should be extremely functionally cohesive,
                    contributing one significant behavior on behalf of the overall application.
                Transactions
                    Bounded contexts are business workflows, and often the entities that need to
                    cooperate in a transaction show architects a good service boundary. Because
                    transactions cause issues in distributed architectures, if architects can design
                    their system to avoid them, they generate better designs.
                Choreography
                    If an architect builds a set of services that offer excellent domain isolation yet
                    require extensive communication to function, the architect may consider bundling
                    these services back into a larger service to avoid the communication
                    overhead.

            Iteration is the only way to ensure good service design. Architects rarely discover the
            perfect granularity, data dependencies, and communication styles on their first pass.

        Data Isolation
            Another requirement of microservices, driven by the bounded context concept, is
            data isolation. Many other architecture styles use a single database for persistence.
            However, microservices tries to avoid all kinds of coupling, including shared schemas
            and databases used as integration points.

            Data isolation is another factor an architect must consider when looking at service
            granularity. Architects must be wary of the entity trap (discussed in “Entity trap” on
            page 110) and not simply model their services to resemble single entities in a
            database.

!!!         Architects are accustomed to using relational databases to unify values within a sys‐
            tem, creating a single source of truth, which is no longer an option when distributing
            data across the architecture. Thus, architects must decide how they want to handle
            this problem: either identifying one domain as the source of truth for some fact and
            coordinating with it to retrieve values or using database replication or caching to dis‐
            tribute information.

    API Layer
        Most pictures of microservices include an API layer sitting between the consumers of
        the system (either user interfaces or calls from other systems), but it is optional. It is
        common because it offers a good location within the architecture to perform useful
        tasks, either via indirection as a proxy or a tie into operational facilities, such as a
        naming service

    Operational Reuse
        Given that microservices prefers duplication to coupling, how do architects handle
        the parts of architecture that really do benefit from coupling, such as operational con‐
        cerns like monitoring, logging, and circuit breakers? One of the philosophies in the
        traditional service-oriented architecture was to reuse as much functionality as possi‐
        ble, domain and operational alike. In microservices, architects try to split these two
        concerns.

!!      Once a team has built several microservices, they realize that each has common ele‐
        ments that benefit from similarity.
        The sidecar pattern offers a solution to this problem
        the common operational concerns appear within each service as a
        separate component, which can be owned by either individual teams or a shared
        infrastructure team. The sidecar component handles all the operational concerns that
        teams benefit from coupling together. Thus, when it comes time to upgrade the mon‐
        itoring tool, the shared infrastructure team can update the sidecar, and each micro‐
        services receives that new functionality.

        Once teams know that each service includes a common sidecar, they can build a ser‐
        vice mesh, allowing unified control across the architecture for concerns like logging
        and monitoring. The common sidecar components connect to form a consistent
        operational interface across all microservices,

            Dan: see "17-3 service plane"

!!!!!   Architects use service discovery as a way to build elasticity into microservices archi‐
        tectures. Rather than invoke a single service, a request goes through a service discov‐
        ery tool, which can monitor the number and frequency of requests, as well as spin up
        new instances of services to handle scale or elasticity concerns. Architects often
        include service discovery in the service mesh, making it part of every microservice.

    Frontends
        Microservices favors decoupling, which would ideally encompass the user interfaces
        as well as backend concerns. In fact, the original vision for microservices included the
        user interface as part of the bounded context, faithful to the principle in DDD. How‐
        ever, practicalities of the partitioning required by web applications and other external
        constraints make that goal difficult. Thus, two styles of user interfaces commonly
        appear for microservices architectures;

!!!     the monolithic frontend features a single user interface that calls
        through the API layer to satisfy user requests. The frontend could be a rich desktop,
        mobile, or web application. For example, many web applications now use a JavaScript
        web framework to build a single user interface.

!!!!    The second option for user interfaces uses microfrontends
            Dan: see "17-6 microfrontend pattern in microservices"
        this approach utilizes components at the user interface level to create a
        synchronous level of granularity and isolation in the user interface as the backend
        services. Each service emits the user interface for that service, which the frontend
        coordinates with the other emitted user interface components. Using this pattern,
        teams can isolate service boundaries from the user interface to the backend services,
        unifying the entire domain within a single team.

!!!!!   Developers can implement the microfrontend pattern in a variety of ways, either
        using a component-based web framework such as React or using one of several open
        source frameworks that support this pattern.

    Communication
        In microservices, architects and developers struggle with appropriate granularity,
        which affects both data isolation and communication. Finding the correct communi‐
        cation style helps teams keep services decoupled yet still coordinated in useful ways.
        Fundamentally, architects must decide on synchronous or asynchronous communica‐
        tion. Synchronous communication requires the caller to wait for a response from the
        callee. Microservices architectures typically utilize protocol-aware heterogeneous inter‐
        operability. We’ll break down that term for you:

            Protocol-aware
                Because microservices usually don’t include a centralized integration hub to
                avoid operational coupling, each service should know how to call other services.
                Thus, architects commonly standardize on how particular services call each
                other: a certain level of REST, message queues, and so on. That means that serv‐
                ices must know (or discover) which protocol to use to call other services.

            Heterogeneous
                Because microservices is a distributed architecture, each service may be written
                in a different technology stack. Heterogeneous suggests that microservices fully
                supports polyglot environments, where different services use different platforms.

            Interoperability
                Describes services calling one another. While architects in microservices try to
                discourage transactional method calls, services commonly call other services via
                the network to collaborate and send/receive information.

        For asynchronous communication, architects often use events and messages, thus
        internally utilizing an event-driven architecture, covered in Chapter 14; the broker
        and mediator patterns manifest in microservices as choreography and orchestration

        Choreography and Orchestration
            Choreography utilizes the same communication style as a broker event-driven archi‐
            tecture. In other words, no central coordinator exists in this architecture, respecting
            the bounded context philosophy. Thus, architects find it natural to implement decou‐
            pled events between services.
            In choreography, each service calls other services as needed, without a central media‐
            tor.

            Because microservices architectures don’t include a global mediator like other
            service-oriented architectures, if an architect needs to coordinate across several serv‐
            ices, they can create their own localized mediator.
            In Figure 17-8, the developers create a service whose sole responsibility is coordinat‐
            ing the call to get all information for a particular customer

            In Figure 17-9, the first service called must coordinate across a wide variety of other
            services, basically acting as a mediator in addition to its other domain responsibili‐
            ties. This pattern is called the front controller pattern, where a nominally choreo‐
            graphed service becomes a more complex mediator for some problem. The downside
            to this pattern is added complexity in the service.

        Transactions and Sagas
            Architects aspire to extreme decoupling in microservices, but then often encounter
            the problem of how to do transactional coordination across services. Because the
            decoupling in the architecture encourages the same level for the databases, atomicity
            that was trivial in monolithic applications becomes a problem in distributed ones.

!!!!!!!!!   Building transactions across service boundaries violates the core decoupling principle
            of the microservices architecture. The best advice for architects who want to do transac‐
            tions across services is: don’t! Fix the granularity components instead. Often,
            architects who build microservices architectures who then find a need to wire them
            together with transactions have gone too granular in their design

            Exceptions do exist
            A popular distributed transactional pattern in microservices is the saga pattern, illus‐
            trated in Figure 17-11.
                Dan: see "17-11 saga transactions in microservices pattern"
            a service acts a mediator across multiple service calls and coordi‐
            nates the transaction. The mediator calls each part of the transaction, records success
            or failure, and coordinates results. If everything goes as planned, all the values in the
            services and their contained databases update synchronously.

            A few transactions across services is sometimes necessary; if it’s the
            dominant feature of the architecture, mistakes were made!

    Architecture Characteristics Ratings
        Dan: see "17-13 architecture characteristic ratings for microservices"

        Notable is the high support for modern engineering practices such as automated
        deployment, testability, and others not listed. Microservices couldn’t exist without the
        DevOps revolution and the relentless march toward automating operational concerns

        As microservices is a distributed architecture, it suffers from many of the deficiencies
        inherent in architectures made from pieces wired together at runtime. Thus, fault tol‐
        erance and reliability are impacted when too much interservice communication is
        used. However, these ratings only point to tendencies in the architecture; developers
        fix many of these problems by redundancy and scaling via service discovery. Under
        normal circumstances, however, independent, single-purpose services generally lead
        to high fault tolerance, hence the high rating for this characteristic within a microser‐
        vices architecture.

        The high points of this architecture are scalability, elasticity, and evolutionary. Some
        of the most scalable systems yet written have utilized this style to great success. Simi‐
        larly, because the architecture relies heavily on automation and intelligent integration
        with operations, developers can also build elasticity support into the architecture.
        Because the architecture favors high decoupling at an incremental level, it supports
        the modern business practice of evolutionary change, even at the architecture level.

        Performance is often an issue in microservices—distributed architectures must make
        many network calls to complete work, which has high performance overhead, and
        they must invoke security checks to verify identity and access for each endpoint.
        Many patterns exist in the microservices world to increase performance, including
        intelligent data caching and replication to prevent an excess of network calls.

!!!!!
    Additional References
        While our goal in this chapter was to touch on some of the significant aspects of this
        architecture style, many excellent resources exist to get further and more detailed
        about this architecture style. Additional and more detailed information can be found
        about microservices in the following references:
        • Building Microservices by Sam Newman (O’Reilly)
        • Microservices vs. Service-Oriented Architecture by Mark Richards (O’Reilly)
        • Microservices AntiPatterns and Pitfalls by Mark Richards (O’Reilly)


========================================================================================================================
Chapter 18. Choosing the Appropriate Architecture Style

    It depends! Choosing an architecture style represents the culmination of analysis and thought about tradeoffs
    for architecture characteristics, domain considerations, strategic goals, and a host of other things.
    However contextual the decision is, some general advice exists around choosing an
    appropriate architecture style.

    Shifting “Fashion” in Architecture
        Preferred architecture styles shift over time, driven by a number of factors:
            Observations from the past
                New architecture styles generally arise from observations and pain points from
                past experiences.
            Changes in the ecosystem
                Constant change is a reliable feature of the software development ecosystem—
                everything changes all the time.
                For example, a few years ago, no one knew what Kubernetes was, and now there are multiple
                conferences around the world with thousands of developers. In a few more years,
                Kubernetes may be replaced with some other tool that hasn’t been written yet.
            New capabilities
                When new capabilities arise, architecture may not merely replace one tool with
                another but rather shift to an entirely new paradigm. For example, few architects
                or developers anticipated the tectonic shift caused in the software development
                world by the advent of containers such as Docker.
            External factors
                Many external factors only peripherally associated with software development
                may drive change within an organizations. For example, architects and develop‐
                ers might be perfectly happy with a particular tool, but the licensing cost has
                become prohibitive, forcing a migration to another option.

!!!!    Regardless of where an organization stands in terms of current architecture fashion,
        an architect should understand current industry trends to make intelligent decisions
        about when to follow and when to make exceptions.

    Decision Criteria
        When choosing an architectural style, an architect must take into account all the various
        factors that contribute to the structure for the domain design. Fundamentally, an
        architect designs two things: whatever domain has been specified, and all the other
        structural elements required to make the system a success.

!!!!!!!!Architects should go into the design decision comfortable with the following things:
            The domain
                Architects should understand many important aspects of the domain, especially
                those that affect operational architecture characteristics. Architects don’t have to
                be subject matter experts, but they must have at least a good general understand‐
                ing of the major aspects of the domain under design.
            Architecture characteristics that impact structure
                Architects must discover and elucidate the architecture characteristics needed to
                support the domain and other external factors
            Data architecture
                Architects and DBAs must collaborate on database, schema, and other datarelated concerns. We don’t
                cover much about data architecture in this book; it is
                its own specialization. However, architects must understand the impact that data
                design might have on their design, particularly if the new system must interact
                with an older and/or in-use data architecture.
            Organizational factors
                Many external factors may influence design. For example, the cost of a particular
                cloud vendor may prevent the ideal design. Or perhaps the company plans to
                engage in mergers and acquisitions, which encourages an architect to gravitate
                toward open solutions and integration architectures.
            Knowledge of process, teams, and operational concerns
            Domain/architecture isomorphism
                Some problem domains match the topology of the architecture. For example, the
                microkernel architecture style is perfectly suited to a system that requires customizability.
                Similarly, some problem domains may be particularly ill-suited for some archi‐
                tecture styles. For example, highly scalable systems struggle with large monolithic
                designs because architects find it difficult to support a large number of concur‐
                rent users in a highly coupled code base.

!!!!!! Taking all these things into account, the architect must make several determinations:
!!!!!!     1.Monolith versus distributed
                Using the quantum concepts discussed earlier, the architect must determine if a
                single set of architecture characteristics will suffice for the design, or do different
                parts of the system need differing architecture characteristics? A single set
                implies that a monolith is suitable (although other factors may drive an architect
                toward a distributed architecture), whereas different architecture characteristics
                imply a distributed architecture.

!!!!!!     2.Where should data live?
                If the architecture is monolithic, architects commonly assume a single relational
                databases or a few of them. In a distributed architecture, the architect must
                decide which services should persist data, which also implies thinking about how
                data must flow throughout the architecture to build workflows. Architects must
                consider both structure and behavior when designing architecture and not be
                fearful of iterating on the design to find better combinations.

!!!!!!     3.What communication styles between services—synchronous or asynchronous?
              Once the architect has determined data partitioning, their next design considera‐
              tion is the communication between services—synchronous or asynchronous?
              Synchronous communication is more convenient in most cases, but it can lead to
              scalability, reliability, and other undesirable characteristics. Asynchronous com‐
              munication can provide unique benefits in terms of performance and scale but
              can present a host of headaches: data synchronization, deadlocks, race conditions,
              debugging, and so on.
!!!!!!        Because synchronous communication presents fewer design, implementation, and
              debugging challenges, architects should default to synchronous when possible and
              use asynchronous when necessary

        The output of this design process is architecture topology, taking into account what
        architecture style (and hybridizations) the architect chose, architecture decision
        records about the parts of the design which required the most effort by the architect,
        and architecture fitness functions to protect important principles and operational
        architecture characteristics.


========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
PART 3 Techniques and Soft Skills

    An effective software architect must not only understand the technical aspects of soft‐
    ware architecture, but also the primary techniques and soft skills necessary to think
    like an architect, guide development teams, and effectively communicate the architec‐
    ture to various stakeholders



========================================================================================================================
Chapter 19. Architecture Decisions

    Architecture decisions usually involve the structure of the application or system, but they
    may involve technology decisions as well, particularly when those technology deci‐
    sions impact architecture characteristics. Whatever the context, a good architecture
    decision is one that helps guide development teams in making the right technical
    choices. Making architecture decisions involves gathering enough relevant informa‐
    tion, justifying the decision, documenting the decision, and effectively communicat‐
    ing that decision to the right stakeholders.

    Architecture Decision Anti-Patterns
        Making effective and accurate architecture decisions requires an
        architect to overcome all three of these anti-patterns.

        Covering Your Assets Anti-Pattern
            The first anti-pattern to emerge when trying to make architecture decisions is the
            Covering Your Assets anti-pattern. This anti-pattern occurs when an architect avoids
            or defers making an architecture decision out of fear of making the wrong choice

            There are two ways to overcome this anti-pattern. The first is to wait until the last
            responsible moment to make an important architecture decision. The last responsible
            moment means waiting until you have enough information to justify and validate
            your decision, but not waiting so long that you hold up development teams or fall
            into the Analysis Paralysis anti-pattern. The second way to avoid this anti-pattern is to
            continually collaborate with development teams to ensure that the decision you made
            can be implemented as expected. This is vitally important because it is not feasible as
            an architect to possibly know every single detail about a particular technology and all
            the associated issues. By closely collaborating with development teams, the architect
            can respond quickly to a change in the architecture decision if issues occur.

        Groundhog Day Anti-Pattern
            The Groundhog Day anti-pattern occurs when people don’t know why a decision was
            made, so it keeps getting discussed over and over and over. The Groundhog Day anti pattern gets it name from
            the Bill Murray movie Groundhog Day, where it was February 2 over and over every day.
            The Groundhog Day anti-pattern occurs because once an architect makes an archi‐
            tecture decision, they fail to provide a justification for the decision (or a complete jus‐
!!!!        tification). When justifying architecture decisions it is important to provide both
            technical and business justifications for your decision

            While this is a good example of a technical justification, what is missing is the busi‐
            ness justification—in other words, why should the business pay for this architectural
            refactoring? A good business justification for this decision might be to deliver new
            business functionality faster, therefore improving time to market. Another might be
            to reduce the costs associated with the development and release of new features.
!!!         If a particular architecture decision does not provide any business value, then perhaps it is not
            a good decision and should be reconsidered.

!!!!!!      Four of the most common business justifications include cost, time to market, user
            satisfaction, and strategic positioning. When focusing on these common business jus‐
            tifications, it is important to take into consideration what is important to the business
            stakeholders. Justifying a particular decision based on cost savings alone might not be
            the right decision if the business stakeholders are less concerned about cost and more
            concerned about time to market.

        Email-Driven Architecture Anti-Pattern
            The Email-Driven Architecture anti-pattern is where people lose, forget, or don’t even know an
            architecture decision has been made and therefore cannot possibly implement that architecture decision.
            This anti-pattern is all about effectively communicating your architecture decisions.
            Email is a great tool for communication, but it makes a poor document repository system.

            A better approach is to mention only the nature and context of the decision in the body of the email and pro‐
            vide a link to the single system of record for the actual architecture decision and cor‐
            responding details (whether it be a link to a wiki page or a document in a filesystem).

    Architecturally Significant
        Many architects believe that if the architecture decision involves any specific technol‐
        ogy, then it’s not an architecture decision, but rather a technical decision. This is not
        always true. If an architect makes a decision to use a particular technology because it
        directly supports a particular architecture characteristic (such as performance or scal‐
        ability), then it’s an architecture decision.
        According to Michael, architecturally significant decisions are those
        decisions that affect the structure, nonfunctional characteristics, dependencies, inter‐
        faces, or construction techniques.

    Architecture Decision Records
!!!!!   One of the most effective ways of documenting architecture decisions is through
        Architecture Decision Records (ADRs). ADRs were first evangelized by Michael
        Nygard in a blog post and later marked as “adopt” in the ThoughtWorks Technology
        Radar. An ADR consists of a short text file (usually one to two pages long) describing
        a specific architecture decision. While ADRs can be written using plain text, they are
        usually written in some sort of text document format like AsciiDoc or Markdown.
        Alternatively, an ADR can also be written using a wiki page template.

        Basic Structure
            The basic structure of an ADR consists of five main sections: Title, Status, Context,
            Decision, and Consequences. We usually add two additional sections as part of the
            basic structure: Compliance and Notes. This basic structure (as illustrated in
            Figure 19-1) can be extended to include any other section deemed needed, providing
            the template is kept both consistent and concise. A good example of this might be to
            add an Alternatives section if necessary to provide an analysis of all the other possible
            alternative solutions

            Dan: see "19-1 ADR structure"

            It should have
                -title
                - status (Proposed, Accepted, or Superseded.)
                - context “what situation is forcing me to make this decision?”
                        If an architect is required to document the analysis of each alternative in
                        detail, then an additional Alternatives section can be added to the ADR
                - Decision ...contains the architecture decision, along with a full justification for the decision
                        this section allows an architect to place more emphasis on the why rather than the how. Under‐
                        standing why a decision was made is far more important than understanding how
                        something works.
                - Consequences ..documents the overall impact of an architecture decision. Every architecture decision
                       an architect makes has some sort of impact, both good and bad. Having to specify the
                       impact of an architecture decision forces the architect to think about whether those
                       impacts outweigh the benefits of the decision.
                - Compliance
                      The compliance section of an ADR is not one of the standard sections in an ADR, but
                      it’s one we highly recommend adding. The Compliance section forces the architect to
                      think about how the architecture decision will be measured and governed from a
                      compliance perspective. The architect must decide whether the compliance check for
                      this decision must be manual or if it can be automated using a fitness function. If it
                      can be automated using a fitness function, the architect can then specify in this sec‐
                      tion how that fitness function would be written and whether there are any other
                      changes to the code base are needed to measure this architecture decision for
                      compliance.
                - Notes
                      Another section that is not part of a standard ADR but that we highly recommend
                      adding is the Notes section. This section includes various metadata about the ADR,
                      such as the following:
                      • Original author
                      • Approval date
                      • Approved by
                      • Superseded date
                      • Last modified date
                      • Modified by
                      • Last modification


========================================================================================================================
Chapter 20. Analyzing Architecture Risk

    Every architecture has risk associated with it, whether it be risk involving availability,
    scalability, or data integrity. Analyzing architecture risk is one of the key activities of
    architecture. By continually analyzing risk, the architect can address deficiencies
    within the architecture and take corrective action to mitigate the risk. In this chapter
    we introduce some of the key techniques and practices for qualifying risk, creating
    risk assessments, and identifying risk through an activity called risk storming

    Risk Matrix
        there is a risk matrix architects can leverage to help reduce the level of subjectiveness and qualify the risk
        associated with a particular area of the architecture.

        Dan: see "20-1 matrix architecture risk"

!!!!    When leveraging the risk matrix to qualify the risk, consider the
        impact dimension first and the likelihood dimension second.

    Risk Assessments
        The risk matrix described in the previous section can be used to build what is called a
        risk assessment. A risk assessment is a summarized report of the overall risk of an
        architecture with respect to some sort of contextual and meaningful assessment
        criteria.

        We usually use the universal direction symbol of a plus (+) and minus (-) sign next to
        the risk rating to indicate direction, as illustrated in Figure 20-4. Notice in
        Figure 20-4 that although performance for customer registration is medium (4), the
        direction is a minus sign (red), indicating that it is progressively getting worse and
        heading toward high risk. On the other hand, notice that scalability of catalog check‐
        out is high (6) with a plus sign (green), showing that it is improving. Risk ratings
        without a plus or minus sign indicate that the risk is stable and neither getting better
        nor worse.

    Risk Storming
        No architect can single-handedly determine the overall risk of a system. The reason
        for this is two-fold. First, a single architect might miss or overlook a risk area, and
        very few architects have full knowledge of every part of the system. This is where risk
        storming can help

        Risk storming is a collaborative exercise used to determine architectural risk within a
        specific dimension. Common dimensions (areas of risk) include unproven technol‐
        ogy, performance, scalability, availability (including transitive dependencies), data
        loss, single points of failure, and security. While most risk storming efforts involve
        multiple architects, it is wise to include senior developers and tech leads as well

!!!!    The risk storming effort involves both an individual part and a collaborative part. In
        the individual part, all participants individually (without collaboration) assign risk to
        areas of the architecture using the risk matrix described in the previous section. This
        noncollaborative part of risk storming is essential so that participants don’t influence
        or direct attention away from particular areas of the architecture. In the collaborative
        part of risk storming, all participants work together to gain consensus on risk areas,
        discuss risk, and form solutions for mitigating the risk.

        An architecture diagram is used for both parts of the risk storming effort. For holistic
        risk assessments, usually a comprehensive architecture diagram is used, whereas risk
        storming within specific areas of the application would use a contextual architecture
        diagram. It is the responsibility of the architect conducting the risk storming effort to
        make sure these diagrams are up to date and available to all participants.

!!!!    Risk storming is broken down into three primary activities:
            1. Identification
            2. Consensus
            3. Mitigation
        Identification is always an individual, noncollaborative activity, whereas consensus
        and mitigation are always collaborative and involve all participants working together
        in the same room (at least virtually).

        Identification
            The identification activity of risk storming involves each participant individually
            identifying areas of risk within the architecture

            Most risk storming efforts only involve analyzing one particular dimension (such as
            performance), but there might be times, due to the availability of staff or timing
            issues, when multiple dimensions are analyzed within a single risk storming effort
            (such as performance, scalability, and data loss). When multiple dimensions are ana‐
            lyzed within a single risk storming effort, the participants write the dimension next to
            the risk number on the Post-it notes so that everyone is aware of the specific dimen‐
            sion.

        Consensus
            The consensus activity in the risk storming effort is highly collaborative with the goal
            of gaining consensus among all participants regarding the risk within the architec‐
            ture. This activity is most effective when a large, printed version of the architecture
            diagram is available and posted on the wall. In lieu of a large printed version, an elec‐
            tronic version can be displayed on a large screen.

            Item 1 in the list showed that two participants individually identified the Elastic Load
            Balancer as medium risk (3), whereas one participant identified it as high risk (6). In
            this case the other two participants ask the third participant why they identified the
            risk as high. Suppose the third participant says that they assigned the risk as high
            because if the Elastic Load Balancer goes down, the entire system cannot be accessed.
            While this is true and in fact does bring the overall impact rating to high, the other
            two participants convince the third participant that there is low risk of this happen‐
            ing. After much discussion, the third participant agrees, bringing that risk level down
            to a medium (3). However, the first and second participants might not have seen a
            particular aspect of risk in the Elastic Load Balancer that the third did, hence the need
            for collaboration within this activity of risk storming.

!!!         For unproven or unknown technologies, always assign the highest
            risk rating (9) since the risk matrix cannot be used for this dimension.

        Mitigation
            Once all participants agree on the qualification of the risk areas of the architecture,
            the final and most important activity occurs—risk mitigation. Mitigating risk within
            an architecture usually involves changes or enhancements to certain areas of the
            architecture that otherwise might have been deemed perfect the way they were.

            This activity, which is also usually collaborative, seeks ways to reduce or eliminate the
            risk identified in the first activity. There may be cases where the original architecture
            needs to be completely changed based on the identification of risk, whereas others
            might be a straightforward architecture refactoring, such as adding a queue for back
            pressure to reduce a throughput bottleneck issue.

        Risk storming is not a one-time process. Rather, it is a continuous process through
        the life of any system to catch and mitigate risk areas before they happen in produc‐
        tion. How often the risk storming effort happens depends on many factors, including
        frequency of change, architecture refactoring efforts, and the incremental develop‐
        ment of the architecture.


========================================================================================================================
Chapter 21. Diagramming and Presenting Architecture

    Newly minted architects often comment on how surprised they are at how varied the
    job is outside of technical knowledge and experience, which enabled their move into
    the architect role to begin with. In particular, effective communication becomes criti‐
    cal to an architect’s success. No matter how brilliant an architect’s technical ideas, if
    they can’t convince managers to fund them and developers to build them, their brilli‐
    ance will never manifest.

    Diagramming and presenting architectures are two critical soft skills for architects.
    While entire books exist about each topic, we’ll hit some particular highlights for
    each.

    When visually describing an architecture, the creator often must show different views
    of the architecture. For example, the architect will likely show an overview of the
    entire architecture topology, then drill into individual parts to delve into design details.

    Diagramming
        The topology of architecture is always of interest to architects and developers because
        it captures how the structure fits together and forms a valuable shared understanding
        across the team. Therefore, architects should hone their diagramming skills to razor
        sharpness.

        Tools
            The current generation of diagramming tools for architects is extremely powerful,
            and an architect should learn their tool of choice deeply. However, before going to a
            nice tool, don’t neglect low-fidelity artifacts, especially early in the design process.
            Building very ephemeral design artifacts early prevents architects from becoming
            overly attached to what they have created, an anti-pattern we named the Irrational
            Artifact Attachment anti-pattern.

            Eventually, an architect needs to create nice diagrams in a fancy tool, but make sure
            the team has iterated on the design sufficiently to invest time in capturing something

!!!!!       Powerful tools exist to create diagrams on every platform. While we don’t necessarily
            advocate one over another (we quite happily used OmniGraffle for all the diagrams in
            this book),

        Diagramming Standards: UML, C4, and ArchiMate
            UML
                Architects and developers still use UML class and sequence diagrams to communi‐
                cate structure and workflow, but most of the other UML diagram types have fallen
                into disuse
!!!!        C4
                C4 is a diagramming technique developed by Simon Brown to address deficiencies in
                UML and modernize its approach. The four C’s in C4 are as follows:
                    Context
                        Represents the entire context of the system, including the roles of users and
                        external dependencies.
                    Container
                        The physical (and often logical) deployment boundaries and containers within
                        the architecture. This view forms a good meeting point for operations and
                        architects.
                    Component
                        The component view of the system; this most neatly aligns with an architect’s
                        view of the system.
                    Class
                        C4 uses the same style of class diagrams from UML, which are effective, so there
                        is no need to replace them.

!!!     Diagram Guidelines
            Here are some general guidelines to use when creating technical diagrams

                Titles
                    Make sure all the elements of the diagram have titles or are well known to the audience

                Lines
                    Lines should be thick enough to see well. If lines indicate information flow, then use
                    arrows to indicate directional or two-way traffic. Different types of arrowheads might
                    suggest different semantics, but architects should be consistent.
                    Generally, one of the few standards that exists in architecture diagrams is that solid
                    lines tend to indicate synchronous communication and dotted lines indicate asyn‐
                    chronous communication.

                Labels
                    Architects should label each item in a diagram, especially if there is any chance of
                    ambiguity for the readers

    Presenting
        The other soft skill required by modern architects is the ability to conduct effective
        presentations using tools like PowerPoint and Keynote. These tools are the lingua
        franca of modern organizations, and people throughout the organization expect com‐
        petent use of these tools. Unfortunately, unlike word processors and spreadsheets, no
        one seems to spend much time studying how to use these tools well.

        Presentation Patterns makes an important observation about the fundamental differ‐
        ence between creating a document versus a presentation to make a case for some‐
        thing—time. In a presentation, the presenter controls how quickly an idea is
        unfolding, whereas the reader of a document controls that. Thus, one of the most
        important skills an architect can learn in their presentation tool of choice is how to
        manipulate time.

        Manipulating Time
            Presentation tools offer two ways to manipulate time on slides: transitions and ani‐
            mations. Transitions move from slide to slide, and animations allow the designer to
            create movement within a slide. Typically, presentation tools allow just one transition
            per slide but a host of animations for each element: build in (appearance), build out
            (disappearance), and actions (such as movement, scale, and other dynamic behavior).

            One common antipattern called out in Presentation Patterns named Cookie-Cutter states that ideas
            don’t have a predetermined word count, and accordingly, designers shouldn’t artifi‐
            cially pad content to make it appear to fill a slide. Similarly, many ideas are bigger
            than a single slide. Using subtle combinations of transitions and animations such as
            dissolve allows presenters to hide individual slide boundaries, stitching together a set
            of slides to tell a single story. To indicate the end of a thought, presenters should use a
            distinctly different transition (such as door or cube) to provide a visual clue that they
            are moving to a different topic.

        Incremental Builds
            When presenting, the speaker has two information channels: verbal and visual. By
            placing too much text on the slides and then saying essentially the same words, the
            presenter is overloading one information channel and starving the other. The better
            solution to this problem is to use incremental builds for slides, building up (hopefully
            graphical) information as needed rather than all at once.

        Invisibility
            Invisibility is a simple pattern where the presenter inserts a blank black slide within a
            presentation to refocus attention solely on the speaker. If someone has two informa‐
            tion channels (slides and speaker) and turns one of them off (the slides), it automati‐
            cally adds more emphasis to the speaker. Thus, if a presenter wants to make a point,
            insert a blank slide—everyone in the room will focus their attention back on the
            speaker because they are now the only interesting thing in the room to look at.


========================================================================================================================
Chapter 22. Making Teams Effective

    In addition to creating a technical architecture and making architecture decisions, a
    software architect is also responsible for guiding the development team through the
    implementation of the architecture. Software architects who do this well create effec‐
    tive development teams that work closely together to solve problems and create win‐
    ning solutions. While this may sound obvious, too many times we’ve seen architects
    ignore development teams and work in siloed environments to create an architecture.

    Team Boundaries
        It’s been our experience that a software architect can significantly influence the suc‐
        cess or failure of a development team. Teams that feel left out of the loop or estranged
        from software architects (and also the architecture) often do not have the right level
        of guidance and right level of knowledge about various constraints on the system, and
        consequently do not implement the architecture correctly

        Architects that create too many constraints form a tight box around the development
        teams, preventing access to many of the tools, libraries, and practices that are
        required to implement the system effectively. This causes frustration within the team,
        usually resulting in developers leaving the project for happier and healthier
        environments.
        The opposite can also happen. A software architect can create constraints that are too
        loose (or no constraints at all), leaving all of the important architecture decisions to
        the development team. In this scenario, which is just as bad as tight constraints, the
        team essentially takes on the role of a software architect, performing proof of con‐
        cepts and battling over design decisions without the proper level of guidance, result‐
        ing in unproductiveness, confusion, and frustration

        An effective software architect strives to provide the right level of guidance and con‐
        straints so that the team has the correct tools and libraries in place to effectively
        implement the architecture. The rest of this chapter is devoted to how to create these
        effective boundaries.

!!! Architect Personalities
        There are three basic types of architect personalities:
            - a control freak architect
                The control freak architect tries to control every detailed aspect of the software devel‐
                opment process. Every decision a control freak architect makes is usually too finegrained and too low-level, resulting in too many constraints on the development
                team.
                Control freak architects might also
                place tight restrictions on naming conventions, class design, method length, and so
                on. They might even go so far as to write pseudocode for the development teams.
                Essentially, control freak architects steal the art of programming away from the devel‐
                opers, resulting in frustration and a lack of respect for the architect.
                It is very easy to become a control freak architect, particularly when transitioning
                from developer to architect. An architect’s role is to create the building blocks of the
                application (the components) and determine the interactions between those compo‐
                nents. The developer’s role in this effort is to then take those components and deter‐
                mine how they will be implemented using class diagrams and design patterns.
                However, in the transition from developer to architect, it is all too tempting to want
                to create the class diagrams and design patterns as well since that was the newly min‐
                ted architect’s prior role.
            - an armchair architect
                The armchair architect is the type of architect who hasn’t coded in a very long time (if
                at all) and doesn’t take the implementation details into account when creating an
                architecture. They are typically disconnected from the development teams
                In some cases the armchair architect is simply in way over their head in terms of the
                technology or business domain and therefore cannot possibly lead or guide teams
                from a technical or business problem standpoint. For example, what do developers
                do? Why, they code, of course. Writing program code is really hard to fake; either a
!!!!!!!!!       developer writes software code, or they don’t. However, what does an architect do?
                No one knows! Most architects draw lots of lines and boxes—but how detailed should
                an architect be in those diagrams? Here’s a dirty little secret about architecture—it’s
                really easy to fake it as an architect!

                In this scenario, development teams end up taking on the role of
                architect, essentially doing the work an architect is supposed to be doing. Team veloc‐
                ity and productivity suffer as a result, and teams get confused about how the system
                should work.

            - an effective architect
                An effective software architect produces the appropriate constraints and boundaries
                on the team, ensuring that the team members are working well together and have the
                right level of guidance on the team. The effective architect also ensures that the team
                has the correct and appropriate tools and technologies in place.

        Each personality matches a particular boundary type discussed in the
        prior section on team boundaries: control freak architects produce tight boundaries,
        armchair architects produce loose boundaries, and effective architects produce just
        the right kinds of boundaries.

    How Much Control?
        Becoming an effective software architect is knowing how much control to exert on a
        given development team. This concept is known as Elastic Leadership and is widely
        evangelized by author and consultant Roy Osherove. We’re going to deviate a bit from
        the work Osherove has done in this area and focus on specific factors for software
        architecture.

        Knowing how much an effective software architect should be a control freak and how
        much they should be an armchair architect involves five main factors. These factors
        also determine how many teams (or projects) a software architect can manage at
        once:
            Team familiarity
                How well do the team members know each other? Have they worked together
                before on a project? Generally, the better team members know each other, the
                less control is needed because team members start to become self-organizing.
            Team size
                How big is the team? (We consider more than 12 developers on the same team to
                be a big team, and 4 or fewer to be a small team.) The larger the team, the more
                control is needed. The smaller the team, less control is needed.
            Overall experience
                How many team members are senior? How many are junior? Is it a mixed team
                of junior and senior developers? How well do they know the technology and
                business domain? Teams with lots of junior developers require more control and
                mentoring, whereas teams with more senior developers require less control
            Project complexity
                Is the project highly complex or just a simple website? Highly complex projects
                require the architect to be more available to the team and to assist with issues
            Project duration
                Is the project short (two months), long (two years), or average duration (six
                months)? The shorter the duration, the less control is needed; conversely, the
                longer the project, the more control is needed.

    Team Warning Signs
!!!     Process loss, otherwise known as Brook’s law, was originally coined by Fred Brooks in
        his book The Mythical Man Month (Addison-Wesley). The basic idea of process loss is
        that the more people you add to a project, the more time the project will take. As
        illustrated in Figure 22-9, the group potential is defined by the collective efforts of
        everyone on the team. However, with any team, the actual productivity will always be
        less than the group potential, the difference being the process loss of the team

        An effective software architect will observe the development team and look for pro‐
        cess loss. Process loss is a good factor in determining the correct team size for a par‐
        ticular project or effort. One indication of process loss is frequent merge conflicts
        when pushing code to a repository. This is an indication that team members are pos‐
        sibly stepping on each other’s toes and working on the same code. Looking for areas
        of parallelism within the team and having team members working on separate serv‐
        ices or areas of the application is one way to avoid process loss

        Diffusion of responsibility is based on the fact that as team size increases, it has a
        negative impact on communication. Confusion about who is responsible for what on
        the team and things getting dropped are good signs of a team that is too large

    Leveraging Checklists
        Airline pilots use checklists on every flight—even the most experienced, seasoned
        veteran pilots. Pilots have checklists for takeoff, landing, and thousands of other sit‐
        uations, both common and unusual edge cases. They use checklists because one
        missed aircraft setting (such as setting the flaps to 10 degrees) or procedure (such as
        gaining clearance into a terminal control area) can mean the difference between a
        safe flight and a disastrous one.

        Checklists work. They provide an excellent vehicle for making sure everything is cov‐
        ered and addressed. If checklists work so well, then why doesn’t the software develop‐
        ment industry leverage them? We firmly believe through personal experience that
        checklists make a big difference in the effectiveness of development teams

        Architects find that checklists do,
        in fact, make development teams more effective, and as such start to make everything
        a checklist, invoking what is known as the law of diminishing returns. The more
        checklists an architect creates, the less chance developers will use them. Another key
        success factor when creating checklists is to make them as small as possible while still
        capturing all the necessary steps within a process.

        Three key checklists that we’ve found to be most effective are a developer code comple‐
        tion checklist, a unit and functional testing checklist, and a software release checklist

!!!!    Hawthorne effect essentially means that if people know they are being observed or
        monitored, their behavior changes, and generally they will do the right thing. Exam‐
        ples include highly visible cameras in and around buildings that actually don’t work
        or aren’t really recording anything
        The Hawthorne effect can be used to govern the use of checklists as well. An architect
        can let the team know that the use of checklists is critical to the team’s effectiveness,
        and as a result, all checklists will be verified to make sure the task was actually per‐
        formed, when in fact the architect is only occasionally spot-checking the checklists
        for correctness

        Developer Code Completion Checklist
            The developer code completion checklist is an effective tool to use, particularly when
            a software developer states that they are “done” with the code. It also is useful for
            defining what is known as the “definition of done.”

                Dan: see "22-12 developer code completion checklist" for an example

        Unit and Functional Testing Checklist
            Perhaps one of the most effective checklists is a unit and functional testing checklist.
            This checklist contains some of the more unusual and edge-case tests that software
            developers tend to forget to test. Whenever someone from QA finds an issue with the
            code based on a particular test case, that test case should be added to this checklist.
            This particular checklist is usually one of the largest ones due to all the types of tests
            that can be run against code. The purpose of this checklist is to ensure the most com‐
            plete coding possible so that when the developer is done with the checklist, the code
            is essentially production ready

            Here are some of the items found in a typical unit and functional testing checklist:
            • Special characters in text and numeric fields
            • Minimum and maximum value ranges
            • Unusual and extreme test cases
            • Missing fields

            any items that can be written as automated tests should be removed from the checklist.

        Software Release Checklist
            Releasing software into production is perhaps one of the most error-prone aspects of
            the software development life cycle, and as such makes for a great checklist. This
            checklist helps avoid failed builds and failed deployments, and it significantly reduces
            the amount of risk associated with releasing software.

            Here are some of the items typically included within the software release checklist:
                • Configuration changes in servers or external configuration servers
                • Third-party libraries added to the project (JAR, DLL, etc.)
                • Database updates and corresponding database migration scripts

    Providing Guidance
!!!!    Using this example, an effective software architect can provide guidance to the development
        team by first having the developer answer the following questions:
            1. Are there any overlaps between the proposed library and existing functionality within the
            system?
            2. What is the justification for the proposed library?


========================================================================================================================
Chapter 23. Negotiation and Leadership Skills

    Negotiation and leadership skills are hard skills to obtain. It takes many years of
    learning, practice, and “lessons learned” experiences to gain the necessary skills to
    become an effective software architect. Knowing that this book cannot make an
    architect an expert in negotiation and leadership overnight, the techniques intro‐
    duced in this chapter provide a good starting point for gaining these important skills.

    Negotiation and Facilitation
        In the beginning of this book, we listed the core expectations of an architect, the last
        being the expectation that a software architect must understand the political climate
        of the enterprise and be able to navigate the politics. The reason for this key expecta‐
        tion is that almost every decision a software architect makes will be challenged

        Effective software architects understand the politics of the organization, have strong
        negotiation and facilitation skills, and can overcome disagreements when they occur
        to create solutions that all stakeholders agree on.

        Negotiating with Business Stakeholders
            Leverage the use of grammar and buzzwords to better understand the situation.

            Gather as much information as possible before entering into a negotiation.

            When all else fails, state things in terms of cost and time.
                (We recommend saving this negotiation tactic for last)

            Leverage the “divide and conquer” rule to qualify demands or requirements.

        Negotiating with Other Architects
            Always remember that demonstration defeats discussion.
                (By running a comparison between the two options in a production-like environment and
                showing the other architect the results, the argument would likely be avoided.)

            Avoid being too argumentative or letting things get too personal in
            a negotiation—calm leadership combined with clear and concise
            reasoning will always win a negotiation.

        Negotiating with Developers
            When convincing developers to adopt an architecture decision or
            to do a specific task, provide a justification rather than “dictating
            from on high.”

            If a developer disagrees with a decision, have them arrive at the sol‐
            ution on their own.

    The Software Architect as a Leader
        A software architect is also a leader, one who can guide a development team through
!!!!!   the implementation of the architecture. We maintain that about 50% of being an
        effective software architect is having good people skills, facilitation skills, and leader‐
        ship skills.

        An effective way of avoiding accidental complexity is what we call the 4 C’s of archi‐
        tecture: communication, collaboration, clarity, and conciseness. These factors
        all work together to create an effective communicator and collaborator on the team.

        While architects need to be visionaries, they also need to apply practical and realistic
        solutions. Being pragmatic is taking all of the following factors and constraints into
        account when creating an architectural solution:
            • Budget constraints and other cost-based factors
            • Time constraints and other time-based factors
            • Skill set and skill level of the development team
            • Trade-offs and implications associated with an architecture decision
            • Technical limitations of a proposed architectural design or solution

        To lead a team and become an effective leader, a software architect should try to
        become the go-to person on the team—the person developers go to for their ques‐
        tions and problems. An effective software architect will seize the opportunity and
        take the initiative to lead the team, regardless of their title or role on the team. When
        a software architect observes someone struggling with a technical issue, they should
        step in and offer help or guidance

!!!!!!! Suppose an architect observes a team member that comes into work looking sort
        of depressed and bothered—clearly something is up. In this circumstance, an effec‐
        tive software architect would notice the situation and offer to talk—something like,
        “Hey, Antonio, I’m heading over to get some coffee. Why don’t we head over
        together?”

        Ask for the meeting agenda ahead of time to help qualify if you are
        really needed at the meeting or not.

        When calling a meeting, an architect should always try to schedule meetings either first thing in
        the morning, right after lunch, or toward the end of the day, but not during the day
        when most developers experience flow state.


========================================================================================================================
Chapter 24. Developing a Career Path

    Becoming an architect takes time and effort, but based on the many reasons we’ve
    outlined throughout this book, managing a career path after becoming an architect is
    equally tricky. While we can’t chart a specific career path for you, we can point you to
    some practices that we have seen work well.
    An architect must continue to learn throughout their career. The technology world
    changes at a dizzying pace

    Talking to colleagues or experts about what resources they use to keep current is one good way of
    seeking out the latest newsfeeds, websites, and groups that are active in a particular
    area of interest.

    The 20-Minute Rule
        technology breadth is more important to architects than
        depth. However, maintaining breadth takes time and effort, something architects
        should build into their day. But how in the world does anyone have the time to
        actually go to various websites to read articles, watch presentations, and listen to pod‐
        casts? The answer is…not many do. Developers and architects alike struggle with the
        balance of working a regular job, spending time with the family, being available for
        our children, carving out personal time for interests and hobbies, and trying to
        develop careers, while at the same time trying to keep up with the latest trends and
        buzzwords.

!!!!    One technique we use to maintain this balance is something we call the 20-minute
        rule. The idea of this technique is to devote at least 20
        minutes a day to your career as an architect by learning something new or diving
        deeper into a specific topic. Figure 24-1 illustrates examples of some of the types of
        resources to spend 20 minutes a day on, such as InfoQ, DZone Refcardz, and the
        ThoughtWorks Technology Radar. Spend that minimum of 20 minutes to Google
        some unfamiliar buzzwords (“the things you don’t know you don’t know” from Chap‐
        ter 2) to learn a little about them, promoting that knowledge into the “things you
        know you don’t know.”
        We strongly recommend leveraging the 20-minute rule first thing in the morning, as
        the day is starting

!!!!!!Developing a Personal Radar
        a technology radar is a living document to assess the risks and
        rewards of existing and nascent technologies. The radar concept comes from ThoughtWorks;

        Parts
        The ThoughtWorks Radar consists of four quadrants that attempt to cover most of
        the software development landscape:
            Tools
                Tools in the software development space, everything from developers tools like
                IDEs to enterprise-grade integration tools
            Languages and frameworks
                Computer languages, libraries, and frameworks, typically open source
            Techniques
                Any practice that assists software development overall; this may include software
                development processes, engineering practices, and advice
            Platforms
                Technology platforms, including databases, cloud vendors, and operating systems

        Rings
        The Radar has four rings, listed here from outer to inner:
            Hold
                The original intent of the hold ring was “hold off for now,” to represent technolo‐
                gies that were too new to reasonably assess yet—technologies that were getting
                lots of buzz but weren’t yet proven. The hold ring has evolved into indicating
                “don’t start anything new with this technology.” There’s no harm in using it on
                existing projects, but developers should think twice about using it for new
                development.
            Assess
                The assess ring indicates that a technology is worth exploring with the goal of
                understanding how it will affect an organization. Architects should invest some
                effort (such as development spikes, research projects, and conference sessions) to
                see if it will have an impact on the organization. For example, many large compa‐
                nies visibly went through this phase when formulating a mobile strategy
            Trial
                The trial ring is for technologies worth pursuing; it is important to understand
                how to build up this capability. Now is the time to pilot a low-risk project so that
                architects and developers can really understand the technology.
            Adopt
                For technologies in the adopt ring, ThoughtWorks feels strongly that the industry
                should adopt those items.

        Dan see "24-2 technology radar"

        Architects should choose some technologies and/or skills that are widely in demand
        and track that demand. But they might also want to try some technology gambits, like
        open source or mobile development. Anecdotes abound about developers who freed
        themselves from cubicle-dwelling servitude by working late at night on open source
        projects that became popular, purchasable, and eventually, career destinations. This is
        yet another reason to focus on breadth rather than depth.

    Parting Words of Advice
        How do we get great designers? Great designers design, of course.
            —Fred Brooks

!!!!!   So how are we supposed to get great architects, if they only get the chance to architect
        fewer than a half-dozen times in their career?
            —Ted Neward

        Practice is the proven way to build skills and become better at anything in life…
        including architecture. We encourage new and existing architects to keep honing
        their skills, both for individual technology breadth but also for the craft of designing
        architecture. To that end, check out the architecture katas on the companion website
        for the book. Modeled after the katas used as examples here, we encourage architects
        to use these to practice building skills in architecture

!!!!!!  A common question we get about katas: is there an answer guide somewhere?
        Unfortunately such an answer key does not exist. To quote your author, Neal:
        There are not right or wrong answers in architecture—only trade-offs

        So, our last parting words of advice: always learn, always practice, and go do some architecture!


========================================================================================================================
Chapter Self-assesment questions

    Chapter 1: Introduction
        1. What are the four dimensions that define software architecture?
        2. What is the difference between an architecture decision and a design principle?
        3. List the eight core expectations of a software architect.
        4. What is the First Law of Software Architecture?
    Chapter 2: Architectural Thinking
        1. Describe the traditional approach of architecture versus development and
        explain why that approach no longer works.
        2. List the three levels of knowledge in the knowledge triangle and provide an
        example of each.
        3. Why is it more important for an architect to focus on technical breadth rather
        than technical depth?
        4. What are some of the ways of maintaining your technical depth and remaining
        hands-on as an architect?
    Chapter 3: Modularity
        1. What is meant by the term connascence?
        2. What is the difference between static and dynamic connascence?
        3. What does connascence of type mean? Is it static or dynamic connascence?
        4. What is the strongest form of connascence?
        5. What is the weakest form of connascence?
        6. Which is preferred within a code base—static or dynamic connascence?
    Chapter 4: Architecture Characteristics Defined
        1. What three criteria must an attribute meet to be considered an architecture char‐
        acteristic?
        2. What is the difference between an implicit characteristic and an explicit one?
        Provide an example of each.
        3. Provide an example of an operational characteristic.
        4. Provide an example of a structural characteristic.
        5. Provide an example of a cross-cutting characteristic.
        6. Which architecture characteristic is more important to strive for—availability or
        performance?
    Chapter 5: Identifying Architecture Characteristics
        1. Give a reason why it is a good practice to limit the number of characteristics (“-
        ilities”) an architecture should support.
        2. True or false: most architecture characteristics come from business requirements
        and user stories.
        3. If a business stakeholder states that time-to-market (i.e., getting new features and
        bug fixes pushed out to users as fast as possible) is the most important business
        concern, which architecture characteristics would the architecture need to support?
        4. What is the difference between scalability and elasticity?
        5. You find out that your company is about to undergo several major acquisitions to
        significantly increase its customer base. Which architectural characteristics
        should you be worried about?
    Chapter 6: Measuring and Governing Architecture Characteristics
        1. Why is cyclomatic complexity such an important metric to analyze for architec‐
        ture?
        2. What is an architecture fitness function? How can they be used to analyze an
        architecture?
        3. Provide an example of an architecture fitness function to measure the scalability
        of an architecture.
        4. What is the most important criteria for an architecture characteristic to allow
        architects and developers to create fitness functions?
    Chapter 7: Scope of Architecture Characteristics
        1. What is an architectural quantum, and why is it important to architecture?
        2. Assume a system consisting of a single user interface with four independently
        deployed services, each containing its own separate database. Would this system
        have a single quantum or four quanta? Why?
        3. Assume a system with an administration portion managing static reference data
        (such as the product catalog, and warehouse information) and a customer-facing
        portion managing the placement of orders. How many quanta should this system
        be and why? If you envision multiple quanta, could the admin quantum and
        customer-facing quantum share a database? If so, in which quantum would the
        database need to reside?
    Chapter 8: Component-Based Thinking
        1. We define the term component as a building block of an application—something
        the application does. A component usually consist of a group of classes or source
        files. How are components typically manifested within an application or service?
        2. What is the difference between technical partitioning and domain partitioning?
        Provide an example of each.
        3. What is the advantage of domain partitioning?
        4. Under what circumstances would technical partitioning be a better choice over
        domain partitioning?
        5. What is the entity trap? Why is it not a good approach for component
        identification?
        6. When might you choose the workflow approach over the Actor/Actions
        approach when identifying core components?
    Chapter 9: Architecture Styles
        1. List the eight fallacies of distributed computing.
        2. Name three challenges that distributed architectures have that monolithic architectures don’t.
        3. What is stamp coupling?
        4. What are some ways of addressing stamp coupling?
    Chapter 10: Layered Architecture Style
        1. What is the difference between an open layer and a closed layer?
        2. Describe the layers of isolation concept and what the benefits are of this concept.
        3. What is the architecture sinkhole anti-pattern?
        4. What are some of the main architecture characteristics that would drive you to use a layered architecture?
        5. Why isn’t testability well supported in the layered architecture style?
        6. Why isn’t agility well supported in the layered architecture style?
    Chapter 11: Pipeline Architecture
        1. Can pipes be bidirectional in a pipeline architecture?
        2. Name the four types of filters and their purpose.
        3. Can a filter send data out through multiple pipes?
        4. Is the pipeline architecture style technically partitioned or domain partitioned?
        5. In what way does the pipeline architecture support modularity?
        6. Provide two examples of the pipeline architecture style.
    Chapter 12: Microkernel Architecture
        1. What is another name for the microkernel architecture style?
        2. Under what situations is it OK for plug-in components to be dependent on other
        plug-in components?
        3. What are some of the tools and frameworks that can be used to manage plug-ins?
        4. What would you do if you had a third-party plug-in that didn’t conform to the
        standard plug-in contract in the core system?
        5. Provide two examples of the microkernel architecture style.
        6. Is the microkernel architecture style technically partitioned or domain
        partitioned?
        7. Why is the microkernel architecture always a single architecture quantum?
        8. What is domain/architecture isomorphism?
    Chapter 13: Service-Based Architecture
        1. How many services are there in a typical service-based architecture?
        2. Do you have to break apart a database in service-based architecture?
        3. Under what circumstances might you want to break apart a database?
        4. What technique can you use to manage database changes within a service-based
        architecture?
        5. Do domain services require a container (such as Docker) to run?
        6. Which architecture characteristics are well supported by the service-based architecture style?
        7. Why isn’t elasticity well supported in a service-based architecture?
        8. How can you increase the number of architecture quanta in a service-based architecture?
    Chapter 14: Event-Driven Architecture Style
        1. What are the primary differences between the broker and mediator topologies?
        2. For better workflow control, would you use the mediator or broker topology?
        3. Does the broker topology usually leverage a publish-and-subscribe model with topics or a
        point-to-point model with queues?
        4. Name two primary advantage of asynchronous communications.
        5. Give an example of a typical request within the request-based model.
        6. Give an example of a typical request in an event-based model.
        7. What is the difference between an initiating event and a processing event in
        event-driven architecture?
        8. What are some of the techniques for preventing data loss when sending and
        receiving messages from a queue?
        9. What are three main driving architecture characteristics for using event-driven
        architecture?
        10. What are some of the architecture characteristics that are not well supported in
        event-driven architecture?
    Chapter 15: Space-Based Architecture
        1. Where does space-based architecture get its name from?
        2. What is a primary aspect of space-based architecture that differentiates it from
        other architecture styles?
        3. Name the four components that make up the virtualized middleware within a
        space-based architecture.
        4. What is the role of the messaging grid?
        5. What is the role of a data writer in space-based architecture?
        6. Under what conditions would a service need to access data through the data
        reader?
        7. Does a small cache size increase or decrease the chances for a data collision?
        8. What is the difference between a replicated cache and a distributed cache? Which
        one is typically used in space-based architecture?
        9. List three of the most strongly supported architecture characteristics in spacebased architecture.
        10. Why does testability rate so low for space-based architecture?
    Chapter 16: Orchestration-Driven Service-Oriented Architecture
        1. What was the main driving force behind service-oriented architecture?
        2. What are the four primary service types within a service-oriented architecture?
        3. List some of the factors that led to the downfall of service-oriented architecture.
        4. Is service-oriented architecture technically partitioned or domain partitioned?
        5. How is domain reuse addressed in SOA? How is operational reuse addressed?
    Chapter 17: Microservices Architecture
        1. Why is the bounded context concept so critical for microservices architecture?
        2. What are three ways of determining if you have the right level of granularity in a
        microservice?
        3. What functionality might be contained within a sidecar?
        4. What is the difference between orchestration and choreography? Which does
        microservices support? Is one communication style easier in microservices?
        5. What is a saga in microservices?
        6. Why are agility, testability, and deployability so well supported in microservices?
        7. What are two reasons performance is usually an issue in microservices?
        8. Is microservices a domain-partitioned architecture or a technically partitioned
        one?
        9. Describe a topology where a microservices ecosystem might be only a single
        quantum.
        10. How was domain reuse addressed in microservices? How was operational reuse
        addressed?
    Chapter 18: Choosing the Appropriate Architecture Style
        1. In what way does the data architecture (structure of the logical and physical data
        models) influence the choice of architecture style?
        2. How does it influence your choice of architecture style to use?
        3. Delineate the steps an architect uses to determine style of architecture, data parti‐
        tioning, and communication styles.
        4. What factor leads an architect toward a distributed architecture?
    Chapter 19: Architecture Decisions
        1. What is the covering your assets anti-pattern?
        2. What are some techniques for avoiding the email-driven architecture antipattern?
        3. What are the five factors Michael Nygard defines for identifying something as
        architecturally significant?
        4. What are the five basic sections of an architecture decision record?
        5. In which section of an ADR do you typically add the justification for an architec‐
        ture decision?
        6. Assuming you don’t need a separate Alternatives section, in which section of an
        ADR would you list the alternatives to your proposed solution?
        7. What are three basic criteria in which you would mark the status of an ADR as
        Proposed?
    Chapter 20: Analyzing Architecture Risk
        1. What are the two dimensions of the risk assessment matrix?
        2. What are some ways to show direction of particular risk within a risk assess‐
        ment? Can you think of other ways to indicate whether risk is getting better or
        worse?
        3. Why is it necessary for risk storming to be a collaborative exercise?
        4. Why is it necessary for the identification activity within risk storming to be an
        individual activity and not a collaborative one?
        5. What would you do if three participants identified risk as high (6) for a particular
        area of the architecture, but another participant identified it as only medium (3)?
        6. What risk rating (1-9) would you assign to unproven or unknown technologies?
    Chapter 21: Diagramming and Presenting Architecture
        1. What is irrational artifact attachment, and why is it significant with respect to
        documenting and diagramming architecture?
        2. What do the 4 C’s refer to in the C4 modeling technique?
        3. When diagramming architecture, what do dotted lines between components
        mean?
        4. What is the bullet-riddled corpse anti-pattern? How can you avoid this antipattern when creating presentations?
        5. What are the two primary information channels a presenter has when giving a presentation?
    Chapter 22: Making Teams Effective
        1. What are three types of architecture personalities? What type of boundary does
        each personality create?
        2. What are the five factors that go into determining the level of control you should
        exhibit on the team?
        3. What are three warning signs you can look at to determine if your team is getting
        too big?
        4. List three basic checklists that would be good for a development team.
    Chapter 23: Negotiation and Leadership Skills
        1. Why is negotiation so important as an architect?
        2. Name some negotiation techniques when a business stakeholder insists on five
        nines of availability, but only three nines are really needed.
        3. What can you derive from a business stakeholder telling you “I needed it
        yesterday”?
        4. Why is it important to save a discussion about time and cost for last in a
        negotiation?
        5. What is the divide-and-conquer rule? How can it be applied when negotiating
        architecture characteristics with a business stakeholder? Provide an example.
        6. List the 4 C’s of architecture.
        7. Explain why it is important for an architect to be both pragmatic and visionary.
        8. What are some techniques for managing and reducing the number of meetings
        you are invited to?
    Chapter 24: Developing a Career Path
        1. What is the 20-minute rule, and when is it best to apply it?
        2. What are the four rings in the ThoughtWorks technology radar, and what do
        they mean? How can they be applied to your radar?
        3. Describe the difference between depth and breadth of knowledge as it applies to
        software architects. Which should architects aspire to maximize?


TODO Create a new github project that would be a personal radar on tech information ..related to java, docker,
architecture, security, some UI frameworks maybe like described in Chapter 24 etc
    see https://www.thoughtworks.com/radar/byor

TODO Would be nice to have a small project for each of these architectures...
TODO do some architecture katas
    https://fundamentalsofsoftwarearchitecture.com/katas/list.html

DONE https://martinfowler.com/articles/microservices.html
